{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56ef5700-bd71-4e44-99c4-6f17485d94f5",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "\n",
    "This project is structured into **four major components**, each addressing a critical phase of **time series forecasting** using the **Rossmann Store Sales dataset**:\n",
    "\n",
    "üîπ **Part 1**: Data Ingestion, Exploratory Data Analysis (EDA)\n",
    "\n",
    "We begin by importing the dataset, performing a thorough exploratory analysis, and engineering relevant features to prepare the data for modeling.\n",
    "\n",
    "üîπ **Part 2**: Feature Engineering and Data Visualization\n",
    "\n",
    "üîπ **Part 3**: Classical Time Series Analysis and Forecasting\n",
    "\n",
    "This section focuses on widely adopted forecasting techniques in the data science domain. We will implement and evaluate several standard algorithms, including:\n",
    "\n",
    " - **Statistical Models**: ARIMA, SARIMA\n",
    "    \n",
    " - **Ensemble Methods:** XGBoost, LightGBM\n",
    "    \n",
    " - **Facebook Prophet:** A robust model for time series forecasting with built-in seasonality and holiday effects\n",
    "    \n",
    " - **Deep Learning Models:** LSTM, Temporal Fusion Transformers (TFT), N-BEATS\n",
    "\n",
    "üîπ **Part 4**: Hybrid Time Series Forecasting\n",
    "\n",
    "This advanced section explores hybrid modeling approaches typically used by experienced data scientists. These models combine the strengths of multiple algorithms to improve forecasting accuracy:\n",
    "\n",
    " - **ARIMA + XGBoost**\n",
    "    \n",
    " - **Prophet + LightGBM / XGBoost**\n",
    "    \n",
    " - **Prophet + LSTM**\n",
    "    \n",
    " - **TFT + ARIMA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd832622-b6c7-4b7f-a4ef-26eeea11e6a1",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports Libraries\n",
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21a4ece7-9e78-4878-b52b-28605ad85ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4563f70e-b121-4e17-8522-e90be7726f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Setup and Import Libraries in progress...\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Data Ingestion\n",
    "print(\"Step 1: Setup and Import Libraries in progress...\")\n",
    "time.sleep(1)  # Simulate processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75d6c5fa-aee0-4e1f-9e59-840fdba88e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Rossman Store Sales Time Series Analysis - Part 1\n",
      "============================================================\n",
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Data Manipulation & Processing\n",
    "import os\n",
    "import holidays\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import scipy.stats as stats\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format','{:.2f}'.format)\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Rossman Store Sales Time Series Analysis - Part 1\")\n",
    "print(\"=\"*60)\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28356173-747b-4d1f-8398-e5ccca45e36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup and Import Liraries completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"‚úÖ Setup and Import Liraries completed.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ca539c-3bf4-4d74-bc5a-0b4a77793146",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Restore DataFrame\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62fe0208-c733-4efe-93b4-ebc0c3a98e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b18d13a-bcf7-4377-b468-a9ff17d584e8",
   "metadata": {},
   "source": [
    "## View or Display Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c2f2327-6fa3-4c87-8cb8-57cca0d61d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        store  dayofweek       date  sales  customers  open     promo stateholiday  schoolholiday  isholiday  isschoolDay  day  week month  quarter  year  isweekend\n",
      "982643   1115          2 2013-01-01      0          0     0  No Promo       Public              1       True        False  Tue     1   Jan        1  2013      False\n",
      "982640   1112          2 2013-01-01      0          0     0  No Promo       Public              1       True        False  Tue     1   Jan        1  2013      False\n",
      "982639   1111          2 2013-01-01      0          0     0  No Promo       Public              1       True        False  Tue     1   Jan        1  2013      False\n",
      "982638   1110          2 2013-01-01      0          0     0  No Promo       Public              1       True        False  Tue     1   Jan        1  2013      False\n",
      "982637   1109          2 2013-01-01      0          0     0  No Promo       Public              1       True        False  Tue     1   Jan        1  2013      False\n"
     ]
    }
   ],
   "source": [
    "print(df_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ef996b4e-34d3-421d-a3a5-7c04ff033f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2013-01-01 00:00:00'), Timestamp('2015-06-30 00:00:00'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features['date'].min(), df_features['date'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1bb37c-91f6-46a3-942f-baf191c2993b",
   "metadata": {},
   "source": [
    "### Top 10 Stores - Customers Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd68b56a-08fd-4b73-ba7c-aee9ab7ba27e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Stores Performance Analysis:\n",
      "=======================================================\n",
      "Rank Store ID Avg Customers   % of #1 Store\n",
      "-------------------------------------------------------\n",
      "1    733           3,403        100.0%\n",
      "2    262           3,400         99.9%\n",
      "3    562           3,107         91.3%\n",
      "4    769           3,072         90.2%\n",
      "5    1114          2,653         77.9%\n",
      "6    817           2,605         76.5%\n",
      "7    1097          2,412         70.9%\n",
      "8    335           2,391         70.2%\n",
      "9    259           2,334         68.6%\n",
      "10   251           2,028         59.6%\n",
      "\n",
      "Summary Statistics:\n",
      "-------------------------\n",
      "Total stores analyzed: 1,115\n",
      "Top 10 average: 2,740 customers\n",
      "Performance range: 1,375 customers\n",
      "Standard deviation: 477\n",
      "\n",
      "Comparative Analysis:\n",
      "--------------------\n",
      "Overall store average: 629 customers\n",
      "Top 10 outperform overall average by: 335.7%\n"
     ]
    }
   ],
   "source": [
    "# Simple and robust store analysis\n",
    "store_avg = df_features.groupby('store')['customers'].mean()\n",
    "top10 = store_avg.nlargest(10)\n",
    "\n",
    "print(\"Top 10 Stores Performance Analysis:\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"{'Rank':<4} {'Store ID':<8} {'Avg Customers':<15} {'% of #1 Store':<12}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for i, (store, avg_customers) in enumerate(top10.items(), 1):\n",
    "    pct = (avg_customers / top10.iloc[0]) * 100\n",
    "    print(f\"{i:<4} {store:<8} {avg_customers:>10,.0f}     {pct:>8.1f}%\")\n",
    "\n",
    "print(f\"\\nSummary Statistics:\")\n",
    "print(\"-\" * 25)\n",
    "print(f\"Total stores analyzed: {len(store_avg):,}\")\n",
    "print(f\"Top 10 average: {top10.mean():,.0f} customers\")\n",
    "print(f\"Performance range: {top10.max() - top10.min():,.0f} customers\")\n",
    "print(f\"Standard deviation: {top10.std():.0f}\")\n",
    "\n",
    "print(f\"\\nComparative Analysis:\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"Overall store average: {store_avg.mean():.0f} customers\")\n",
    "print(f\"Top 10 outperform overall average by: {((top10.mean() - store_avg.mean()) / store_avg.mean()) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cef3916-7e62-48af-a825-15fd21d8d0db",
   "metadata": {},
   "source": [
    "### Top 10 Stores - Sales Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f93c4aff-96f2-4fde-a6be-08d30d7c3fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Stores Sales Performance Analysis:\n",
      "=======================================================\n",
      "Rank Store ID Avg Sales       % of #1 Store\n",
      "-------------------------------------------------------\n",
      "1    262      $   20,684        100.0%\n",
      "2    817      $   18,106         87.5%\n",
      "3    562      $   17,985         86.9%\n",
      "4    1114     $   17,098         82.7%\n",
      "5    251      $   15,814         76.5%\n",
      "6    513      $   15,134         73.2%\n",
      "7    842      $   15,118         73.1%\n",
      "8    733      $   14,946         72.3%\n",
      "9    788      $   14,931         72.2%\n",
      "10   383      $   14,294         69.1%\n",
      "\n",
      "Summary Statistics:\n",
      "-------------------------\n",
      "Total stores analyzed: 1,115\n",
      "Top 10 average: $16,411 sales\n",
      "Performance range: $6,390 sales\n",
      "Standard deviation: $2016\n",
      "\n",
      "Comparative Analysis:\n",
      "--------------------\n",
      "Overall store average: $5750 sales\n",
      "Top 10 outperform overall average by: 185.4%\n"
     ]
    }
   ],
   "source": [
    "# Simple and robust sales analysis\n",
    "store_sales = df_features.groupby('store')['sales'].mean()\n",
    "top10 = store_sales.nlargest(10)\n",
    "\n",
    "print(\"Top 10 Stores Sales Performance Analysis:\")\n",
    "print(\"=\" * 55)\n",
    "print(f\"{'Rank':<4} {'Store ID':<8} {'Avg Sales':<15} {'% of #1 Store':<12}\")\n",
    "print(\"-\" * 55)\n",
    "\n",
    "for i, (store, avg_sales) in enumerate(top10.items(), 1):\n",
    "    pct = (avg_sales / top10.iloc[0]) * 100\n",
    "    print(f\"{i:<4} {store:<8} ${avg_sales:>9,.0f}     {pct:>8.1f}%\")\n",
    "\n",
    "print(f\"\\nSummary Statistics:\")\n",
    "print(\"-\" * 25)\n",
    "print(f\"Total stores analyzed: {len(store_sales):,}\")\n",
    "print(f\"Top 10 average: ${top10.mean():,.0f} sales\")\n",
    "print(f\"Performance range: ${top10.max() - top10.min():,.0f} sales\")\n",
    "print(f\"Standard deviation: ${top10.std():.0f}\")\n",
    "\n",
    "print(f\"\\nComparative Analysis:\")\n",
    "print(\"-\" * 20)\n",
    "print(f\"Overall store average: ${store_sales.mean():.0f} sales\")\n",
    "print(f\"Top 10 outperform overall average by: {((top10.mean() - store_sales.mean()) / store_sales.mean()) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795e5796-2080-4de1-b34a-48794d8351ec",
   "metadata": {},
   "source": [
    "### Store Performance Comparison Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c410d23f-c70c-4e92-ab77-6ffc667343ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store Performance Comparison Analysis:\n",
      "================================================================================\n",
      "Store  Customers Rank Avg Customers Sales Rank  Avg Sales    Performance \n",
      "--------------------------------------------------------------------------------\n",
      "251    10                 2,028     5           ‚Ç¨  15,814   Both Top 10 \n",
      "259    9                  2,334     Not Top 10  ‚Ç¨  11,484   Customers Only\n",
      "262    2                  3,400     1           ‚Ç¨  20,684   Both Top 10 \n",
      "335    8                  2,391     Not Top 10  ‚Ç¨  13,321   Customers Only\n",
      "383    Not Top 10         1,825     10          ‚Ç¨  14,294   Sales Only  \n",
      "513    Not Top 10         1,747     6           ‚Ç¨  15,134   Sales Only  \n",
      "562    3                  3,107     3           ‚Ç¨  17,985   Both Top 10 \n",
      "733    1                  3,403     8           ‚Ç¨  14,946   Both Top 10 \n",
      "769    4                  3,072     Not Top 10  ‚Ç¨  10,782   Customers Only\n",
      "788    Not Top 10         1,430     9           ‚Ç¨  14,931   Sales Only  \n",
      "817    6                  2,605     2           ‚Ç¨  18,106   Both Top 10 \n",
      "842    Not Top 10           939     7           ‚Ç¨  15,118   Sales Only  \n",
      "1097   7                  2,412     Not Top 10  ‚Ç¨   9,708   Customers Only\n",
      "1114   5                  2,653     4           ‚Ç¨  17,098   Both Top 10 \n",
      "\n",
      "Comparison Summary:\n",
      "-------------------------\n",
      "Stores in both top 10: 6\n",
      "High customers only: 4\n",
      "High sales only: 4\n",
      "Total unique stores: 14\n",
      "\n",
      "Overlap rate: 60.0% of top 10 lists\n"
     ]
    }
   ],
   "source": [
    "# Simple and robust comparison analysis\n",
    "customers_top10 = df_features.groupby('store')['customers'].mean().nlargest(10)\n",
    "sales_top10 = df_features.groupby('store')['sales'].mean().nlargest(10)\n",
    "\n",
    "# Get all unique stores from both top 10 lists\n",
    "all_stores = list(set(customers_top10.index) | set(sales_top10.index))\n",
    "all_stores.sort()\n",
    "\n",
    "print(\"Store Performance Comparison Analysis:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Store':<6} {'Customers Rank':<14} {'Avg Customers':<13} {'Sales Rank':<11} {'Avg Sales':<12} {'Performance':<12}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for store in all_stores:\n",
    "    # Get customer metrics\n",
    "    if store in customers_top10.index:\n",
    "        cust_rank = list(customers_top10.index).index(store) + 1\n",
    "        cust_avg = customers_top10[store]\n",
    "    else:\n",
    "        cust_rank = \"Not Top 10\"\n",
    "        cust_avg = df_features[df_features['store'] == store]['customers'].mean()\n",
    "    \n",
    "    # Get sales metrics\n",
    "    if store in sales_top10.index:\n",
    "        sales_rank = list(sales_top10.index).index(store) + 1\n",
    "        sales_avg = sales_top10[store]\n",
    "    else:\n",
    "        sales_rank = \"Not Top 10\"\n",
    "        sales_avg = df_features[df_features['store'] == store]['sales'].mean()\n",
    "    \n",
    "    # Determine performance category\n",
    "    if store in customers_top10.index and store in sales_top10.index:\n",
    "        performance = \"Both Top 10\"\n",
    "    elif store in customers_top10.index:\n",
    "        performance = \"Customers Only\"\n",
    "    else:\n",
    "        performance = \"Sales Only\"\n",
    "    \n",
    "    # Format output\n",
    "    cust_rank_str = str(cust_rank) if isinstance(cust_rank, int) else cust_rank\n",
    "    sales_rank_str = str(sales_rank) if isinstance(sales_rank, int) else sales_rank\n",
    "    \n",
    "    print(f\"{store:<6} {cust_rank_str:<14} {cust_avg:>9,.0f}     {sales_rank_str:<11} ‚Ç¨{sales_avg:>8,.0f}   {performance:<12}\")\n",
    "\n",
    "print(f\"\\nComparison Summary:\")\n",
    "print(\"-\" * 25)\n",
    "both_top10 = len(set(customers_top10.index) & set(sales_top10.index))\n",
    "customers_only = len(set(customers_top10.index) - set(sales_top10.index))\n",
    "sales_only = len(set(sales_top10.index) - set(customers_top10.index))\n",
    "\n",
    "print(f\"Stores in both top 10: {both_top10}\")\n",
    "print(f\"High customers only: {customers_only}\")\n",
    "print(f\"High sales only: {sales_only}\")\n",
    "print(f\"Total unique stores: {len(all_stores)}\")\n",
    "\n",
    "if both_top10 > 0:\n",
    "    print(f\"\\nOverlap rate: {(both_top10 / 10) * 100:.1f}% of top 10 lists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228bffc3-2e6c-44db-9c54-5202a5103f95",
   "metadata": {},
   "source": [
    "#### Dual Comparison Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fbd3ce15-dd0d-4baa-a349-af7d00e8ae81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Store Performance Comparison DataFrame:\n",
      "======================================================================\n",
      "Store  Avg Customers Avg Sales    Top Both\n",
      "----------------------------------------------------------------------\n",
      "251        2,028     ‚Ç¨  15,814    Yes     \n",
      "259        2,333     ‚Ç¨       0    No      \n",
      "262        3,400     ‚Ç¨  20,684    Yes     \n",
      "335        2,390     ‚Ç¨       0    No      \n",
      "383            0     ‚Ç¨  14,294    No      \n",
      "513            0     ‚Ç¨  15,133    No      \n",
      "562        3,106     ‚Ç¨  17,984    Yes     \n",
      "733        3,403     ‚Ç¨  14,945    Yes     \n",
      "769        3,071     ‚Ç¨       0    No      \n",
      "788            0     ‚Ç¨  14,930    No      \n",
      "817        2,605     ‚Ç¨  18,105    Yes     \n",
      "842            0     ‚Ç¨  15,117    No      \n",
      "1097       2,412     ‚Ç¨       0    No      \n",
      "1114       2,652     ‚Ç¨  17,097    Yes     \n",
      "\n",
      "Summary:\n",
      "---------------\n",
      "Total stores in comparison: 14\n",
      "Top in both categories: 6\n",
      "Top customers only: 4\n",
      "Top sales only: 4\n",
      "Overlap percentage: 60.0%\n"
     ]
    }
   ],
   "source": [
    "# Create the comparison dataframe\n",
    "customers_top10 = df_features.groupby('store')['customers'].mean().nlargest(10).reset_index().rename(columns={'customers': 'avg_customers'})\n",
    "sales_top10 = df_features.groupby('store')['sales'].mean().nlargest(10).reset_index().rename(columns={'sales': 'avg_sales'})\n",
    "\n",
    "comparison_df = pd.merge(\n",
    "    customers_top10,\n",
    "    sales_top10,\n",
    "    on='store',\n",
    "    how='outer'\n",
    ").fillna(0)\n",
    "\n",
    "# Add the top_both flag\n",
    "comparison_df['top_both'] = (\n",
    "    comparison_df['store'].isin(customers_top10['store']) &\n",
    "    comparison_df['store'].isin(sales_top10['store'])\n",
    ")\n",
    "\n",
    "# Enhanced display\n",
    "print(\"Store Performance Comparison DataFrame:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Store':<6} {'Avg Customers':<13} {'Avg Sales':<12} {'Top Both':<8}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for _, row in comparison_df.iterrows():\n",
    "    customers = int(row['avg_customers']) if row['avg_customers'] > 0 else 0\n",
    "    sales = int(row['avg_sales']) if row['avg_sales'] > 0 else 0\n",
    "    top_both = \"Yes\" if row['top_both'] else \"No\"\n",
    "    \n",
    "    print(f\"{int(row['store']):<6} {customers:>9,}     ‚Ç¨{sales:>8,}    {top_both:<8}\")\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(\"-\" * 15)\n",
    "total_stores = len(comparison_df)\n",
    "both_count = comparison_df['top_both'].sum()\n",
    "customers_only = len(comparison_df[(comparison_df['avg_customers'] > 0) & (~comparison_df['top_both'])])\n",
    "sales_only = len(comparison_df[(comparison_df['avg_sales'] > 0) & (~comparison_df['top_both'])])\n",
    "\n",
    "print(f\"Total stores in comparison: {total_stores}\")\n",
    "print(f\"Top in both categories: {both_count}\")\n",
    "print(f\"Top customers only: {customers_only}\")\n",
    "print(f\"Top sales only: {sales_only}\")\n",
    "print(f\"Overlap percentage: {(both_count/10)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb50e7c-f4b8-4078-81d6-2c9610c55003",
   "metadata": {},
   "source": [
    "#### Daily Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07791c55-68b2-498a-b76f-51a83610ab55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daily Performance Analysis:\n",
      "============================================================\n",
      "Day        Avg Customers Avg Sales    Sales Rank Customer Rank\n",
      "------------------------------------------------------------\n",
      "Mon              813     ‚Ç¨   7,798    1          1           \n",
      "Tue              762     ‚Ç¨   7,006    2          2           \n",
      "Fri              743     ‚Ç¨   6,704    3          3           \n",
      "Wed              721     ‚Ç¨   6,536    4          4           \n",
      "Thu              696     ‚Ç¨   6,216    5          5           \n",
      "Sat              659     ‚Ç¨   5,857    6          6           \n",
      "Sun               36     ‚Ç¨     203    7          7           \n",
      "\n",
      "Daily Performance Summary:\n",
      "------------------------------\n",
      "Best sales day: Mon (‚Ç¨7,798)\n",
      "Best customer day: Mon (813 customers)\n",
      "Worst sales day: Sun (‚Ç¨203)\n",
      "Worst customer day: Sun (36 customers)\n",
      "\n",
      "Performance Range:\n",
      "--------------------\n",
      "Sales range: ‚Ç¨7,595\n",
      "Customer range: 777 customers\n",
      "\n",
      "Insight: Mon leads in both sales and customer traffic!\n"
     ]
    }
   ],
   "source": [
    "# Simple and robust daily analysis\n",
    "day_stats = df_features.groupby(\"day\")[[\"customers\",\"sales\"]].mean().sort_values(by=\"sales\", ascending=False)\n",
    "\n",
    "print(\"Daily Performance Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Day':<10} {'Avg Customers':<13} {'Avg Sales':<12} {'Sales Rank':<10} {'Customer Rank':<12}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Get rankings for both metrics\n",
    "sales_ranking = day_stats.sort_values(by=\"sales\", ascending=False)\n",
    "customers_ranking = day_stats.sort_values(by=\"customers\", ascending=False)\n",
    "\n",
    "for i, (day, row) in enumerate(sales_ranking.iterrows(), 1):\n",
    "    customers = row['customers']\n",
    "    sales = row['sales']\n",
    "    cust_rank = list(customers_ranking.index).index(day) + 1\n",
    "    \n",
    "    print(f\"{day:<10} {customers:>9,.0f}     ‚Ç¨{sales:>8,.0f}    {i:<10} {cust_rank:<12}\")\n",
    "\n",
    "print(f\"\\nDaily Performance Summary:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"Best sales day: {sales_ranking.index[0]} (‚Ç¨{sales_ranking.iloc[0]['sales']:,.0f})\")\n",
    "print(f\"Best customer day: {customers_ranking.index[0]} ({customers_ranking.iloc[0]['customers']:,.0f} customers)\")\n",
    "print(f\"Worst sales day: {sales_ranking.index[-1]} (‚Ç¨{sales_ranking.iloc[-1]['sales']:,.0f})\")\n",
    "print(f\"Worst customer day: {customers_ranking.index[-1]} ({customers_ranking.iloc[-1]['customers']:,.0f} customers)\")\n",
    "\n",
    "print(f\"\\nPerformance Range:\")\n",
    "print(\"-\" * 20)\n",
    "sales_range = sales_ranking.iloc[0]['sales'] - sales_ranking.iloc[-1]['sales']\n",
    "customers_range = customers_ranking.iloc[0]['customers'] - customers_ranking.iloc[-1]['customers']\n",
    "print(f\"Sales range: ‚Ç¨{sales_range:,.0f}\")\n",
    "print(f\"Customer range: {customers_range:,.0f} customers\")\n",
    "\n",
    "# Correlation insight\n",
    "if sales_ranking.index[0] == customers_ranking.index[0]:\n",
    "    print(f\"\\nInsight: {sales_ranking.index[0]} leads in both sales and customer traffic!\")\n",
    "else:\n",
    "    print(f\"\\nInsight: Different peak days - Sales: {sales_ranking.index[0]}, Customers: {customers_ranking.index[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb2ee066-39e1-49ee-993f-f06459892f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monthly Performance Analysis:\n",
      "=================================================================\n",
      "Month      Avg Customers Avg Sales    Sales Rank Customer Rank\n",
      "-----------------------------------------------------------------\n",
      "Dec              703     ‚Ç¨   6,827    1          1           \n",
      "Jul              664     ‚Ç¨   6,023    2          2           \n",
      "Nov              654     ‚Ç¨   6,008    3          3           \n",
      "Mar              629     ‚Ç¨   5,785    4          8           \n",
      "Jun              625     ‚Ç¨   5,761    5          10          \n",
      "Apr              631     ‚Ç¨   5,739    6          7           \n",
      "Aug              642     ‚Ç¨   5,693    7          4           \n",
      "Feb              627     ‚Ç¨   5,645    8          9           \n",
      "Sep              634     ‚Ç¨   5,570    9          5           \n",
      "Oct              631     ‚Ç¨   5,537    10         6           \n",
      "May              602     ‚Ç¨   5,490    11         11          \n",
      "Jan              602     ‚Ç¨   5,465    12         12          \n",
      "\n",
      "Monthly Performance Summary:\n",
      "--------------------------------\n",
      "Best sales month: Dec (‚Ç¨6,827)\n",
      "Best customer month: Dec (703 customers)\n",
      "Worst sales month: Jan (‚Ç¨5,465)\n",
      "Worst customer month: Jan (602 customers)\n",
      "\n",
      "Seasonal Performance Range:\n",
      "-------------------------\n",
      "Sales range: ‚Ç¨1,361\n",
      "Customer range: 101 customers\n",
      "Sales volatility: 23.5%\n",
      "Customer volatility: 15.9%\n",
      "\n",
      "Seasonal Insights:\n",
      "------------------\n",
      "Peak season: Dec leads in both sales and customer traffic!\n",
      "Pattern: Winter holiday season shows strong performance\n"
     ]
    }
   ],
   "source": [
    "# Simple and robust monthly analysis\n",
    "month_stats = df_features.groupby(\"month\")[[\"customers\",\"sales\"]].mean().sort_values(by=\"sales\", ascending=False)\n",
    "\n",
    "# Month variable is already mapped as Jan, Feb, Mar, etc.\n",
    "\n",
    "print(\"Monthly Performance Analysis:\")\n",
    "print(\"=\" * 65)\n",
    "print(f\"{'Month':<10} {'Avg Customers':<13} {'Avg Sales':<12} {'Sales Rank':<10} {'Customer Rank':<12}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "# Get rankings for both metrics\n",
    "sales_ranking = month_stats.sort_values(by=\"sales\", ascending=False)\n",
    "customers_ranking = month_stats.sort_values(by=\"customers\", ascending=False)\n",
    "\n",
    "for i, (month, row) in enumerate(sales_ranking.iterrows(), 1):\n",
    "    customers = row['customers']\n",
    "    sales = row['sales']\n",
    "    cust_rank = list(customers_ranking.index).index(month) + 1\n",
    "    month_name = month\n",
    "    \n",
    "    print(f\"{month_name:<10} {customers:>9,.0f}     ‚Ç¨{sales:>8,.0f}    {i:<10} {cust_rank:<12}\")\n",
    "\n",
    "print(f\"\\nMonthly Performance Summary:\")\n",
    "print(\"-\" * 32)\n",
    "best_sales_month = sales_ranking.index[0]\n",
    "best_customer_month = customers_ranking.index[0]\n",
    "worst_sales_month = sales_ranking.index[-1]\n",
    "worst_customer_month = customers_ranking.index[-1]\n",
    "\n",
    "print(f\"Best sales month: {best_sales_month} (‚Ç¨{sales_ranking.iloc[0]['sales']:,.0f})\")\n",
    "print(f\"Best customer month: {best_customer_month} ({customers_ranking.iloc[0]['customers']:,.0f} customers)\")\n",
    "print(f\"Worst sales month: {worst_sales_month} (‚Ç¨{sales_ranking.iloc[-1]['sales']:,.0f})\")\n",
    "print(f\"Worst customer month: {worst_customer_month} ({customers_ranking.iloc[-1]['customers']:,.0f} customers)\")\n",
    "\n",
    "print(f\"\\nSeasonal Performance Range:\")\n",
    "print(\"-\" * 25)\n",
    "sales_range = sales_ranking.iloc[0]['sales'] - sales_ranking.iloc[-1]['sales']\n",
    "customers_range = customers_ranking.iloc[0]['customers'] - customers_ranking.iloc[-1]['customers']\n",
    "avg_sales = month_stats['sales'].mean()\n",
    "avg_customers = month_stats['customers'].mean()\n",
    "\n",
    "print(f\"Sales range: ‚Ç¨{sales_range:,.0f}\")\n",
    "print(f\"Customer range: {customers_range:,.0f} customers\")\n",
    "print(f\"Sales volatility: {(sales_range/avg_sales)*100:.1f}%\")\n",
    "print(f\"Customer volatility: {(customers_range/avg_customers)*100:.1f}%\")\n",
    "\n",
    "# Seasonal insights\n",
    "print(f\"\\nSeasonal Insights:\")\n",
    "print(\"-\" * 18)\n",
    "if best_sales_month == best_customer_month:\n",
    "    print(f\"Peak season: {best_sales_month} leads in both sales and customer traffic!\")\n",
    "else:\n",
    "    print(f\"Different peak months - Sales: {best_sales_month}, Customers: {best_customer_month}\")\n",
    "\n",
    "# Identify seasonal patterns\n",
    "if best_sales_month in ['Nov', 'Dec', 'Jan']:\n",
    "    print(\"Pattern: Winter holiday season shows strong performance\")\n",
    "elif best_sales_month in ['Jun', 'Jul', 'Aug']:\n",
    "    print(\"Pattern: Summer season shows strong performance\")\n",
    "elif best_sales_month in ['Mar', 'Apr', 'May']:\n",
    "    print(\"Pattern: Spring season shows strong performance\")\n",
    "else:\n",
    "    print(\"Pattern: Fall season shows strong performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8795851d-8333-4227-9f7c-280c30e35c8f",
   "metadata": {},
   "source": [
    "### Yearly Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c150a08e-83f9-4290-b9be-85f7b7c20f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yearly Performance Analysis:\n",
      "======================================================================\n",
      "Year   Avg Customers Avg Sales    Sales Rank Customer Rank YoY Growth\n",
      "----------------------------------------------------------------------\n",
      "2014         643     ‚Ç¨   5,833    1          1            +3.1%     \n",
      "2015         621     ‚Ç¨   5,833    2          3            -0.0%     \n",
      "2013         629     ‚Ç¨   5,659    3          2            Baseline  \n",
      "\n",
      "Yearly Performance Summary:\n",
      "------------------------------\n",
      "Best sales year: 2014 (‚Ç¨5,833)\n",
      "Best customer year: 2014 (643 customers)\n",
      "Worst sales year: 2013 (‚Ç¨5,659)\n",
      "Worst customer year: 2015 (621 customers)\n",
      "\n",
      "Multi-Year Performance Trends:\n",
      "--------------------------------\n",
      "Years analyzed: 3\n",
      "Sales range: ‚Ç¨175\n",
      "Customer range: 22 customers\n",
      "Overall sales trend (2013-2015): +3.1%\n",
      "Overall customer trend (2013-2015): -1.3%\n",
      "\n",
      "Business Insights:\n",
      "------------------\n",
      "Peak performance: 2014 excelled in both sales and customer traffic!\n",
      "Trend: Stable performance with -0.0% change in latest year\n"
     ]
    }
   ],
   "source": [
    "# Simple and robust yearly analysis\n",
    "year_stats = df_features.groupby(\"year\")[[\"customers\",\"sales\"]].mean().sort_values(by=\"sales\", ascending=False)\n",
    "\n",
    "print(\"Yearly Performance Analysis:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Year':<6} {'Avg Customers':<13} {'Avg Sales':<12} {'Sales Rank':<10} {'Customer Rank':<12} {'YoY Growth':<10}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# Get rankings for both metrics\n",
    "sales_ranking = year_stats.sort_values(by=\"sales\", ascending=False)\n",
    "customers_ranking = year_stats.sort_values(by=\"customers\", ascending=False)\n",
    "\n",
    "# Calculate year-over-year growth (chronological order)\n",
    "chronological_years = sorted(year_stats.index)\n",
    "yoy_sales = {}\n",
    "yoy_customers = {}\n",
    "\n",
    "for i, year in enumerate(chronological_years):\n",
    "    if i > 0:\n",
    "        prev_year = chronological_years[i-1]\n",
    "        sales_growth = ((year_stats.loc[year, 'sales'] - year_stats.loc[prev_year, 'sales']) / year_stats.loc[prev_year, 'sales']) * 100\n",
    "        customer_growth = ((year_stats.loc[year, 'customers'] - year_stats.loc[prev_year, 'customers']) / year_stats.loc[prev_year, 'customers']) * 100\n",
    "        yoy_sales[year] = sales_growth\n",
    "        yoy_customers[year] = customer_growth\n",
    "    else:\n",
    "        yoy_sales[year] = 0\n",
    "        yoy_customers[year] = 0\n",
    "\n",
    "for i, (year, row) in enumerate(sales_ranking.iterrows(), 1):\n",
    "    customers = row['customers']\n",
    "    sales = row['sales']\n",
    "    cust_rank = list(customers_ranking.index).index(year) + 1\n",
    "    growth = yoy_sales.get(year, 0)\n",
    "    growth_str = f\"{growth:+.1f}%\" if growth != 0 else \"Baseline\"\n",
    "    \n",
    "    print(f\"{year:<6} {customers:>9,.0f}     ‚Ç¨{sales:>8,.0f}    {i:<10} {cust_rank:<12} {growth_str:<10}\")\n",
    "\n",
    "print(f\"\\nYearly Performance Summary:\")\n",
    "print(\"-\" * 30)\n",
    "best_sales_year = sales_ranking.index[0]\n",
    "best_customer_year = customers_ranking.index[0]\n",
    "worst_sales_year = sales_ranking.index[-1]\n",
    "worst_customer_year = customers_ranking.index[-1]\n",
    "\n",
    "print(f\"Best sales year: {best_sales_year} (‚Ç¨{sales_ranking.iloc[0]['sales']:,.0f})\")\n",
    "print(f\"Best customer year: {best_customer_year} ({customers_ranking.iloc[0]['customers']:,.0f} customers)\")\n",
    "print(f\"Worst sales year: {worst_sales_year} (‚Ç¨{sales_ranking.iloc[-1]['sales']:,.0f})\")\n",
    "print(f\"Worst customer year: {worst_customer_year} ({customers_ranking.iloc[-1]['customers']:,.0f} customers)\")\n",
    "\n",
    "print(f\"\\nMulti-Year Performance Trends:\")\n",
    "print(\"-\" * 32)\n",
    "total_years = len(year_stats)\n",
    "sales_range = sales_ranking.iloc[0]['sales'] - sales_ranking.iloc[-1]['sales']\n",
    "customers_range = customers_ranking.iloc[0]['customers'] - customers_ranking.iloc[-1]['customers']\n",
    "\n",
    "print(f\"Years analyzed: {total_years}\")\n",
    "print(f\"Sales range: ‚Ç¨{sales_range:,.0f}\")\n",
    "print(f\"Customer range: {customers_range:,.0f} customers\")\n",
    "\n",
    "# Calculate overall trend\n",
    "if len(chronological_years) > 1:\n",
    "    first_year = chronological_years[0]\n",
    "    last_year = chronological_years[-1]\n",
    "    overall_sales_growth = ((year_stats.loc[last_year, 'sales'] - year_stats.loc[first_year, 'sales']) / year_stats.loc[first_year, 'sales']) * 100\n",
    "    overall_customer_growth = ((year_stats.loc[last_year, 'customers'] - year_stats.loc[first_year, 'customers']) / year_stats.loc[first_year, 'customers']) * 100\n",
    "    \n",
    "    print(f\"Overall sales trend ({first_year}-{last_year}): {overall_sales_growth:+.1f}%\")\n",
    "    print(f\"Overall customer trend ({first_year}-{last_year}): {overall_customer_growth:+.1f}%\")\n",
    "\n",
    "print(f\"\\nBusiness Insights:\")\n",
    "print(\"-\" * 18)\n",
    "if best_sales_year == best_customer_year:\n",
    "    print(f\"Peak performance: {best_sales_year} excelled in both sales and customer traffic!\")\n",
    "else:\n",
    "    print(f\"Different peak years - Sales: {best_sales_year}, Customers: {best_customer_year}\")\n",
    "\n",
    "# Growth trend analysis\n",
    "if len(chronological_years) > 1:\n",
    "    recent_growth = yoy_sales.get(chronological_years[-1], 0)\n",
    "    if recent_growth > 5:\n",
    "        print(f\"Trend: Strong recent growth of {recent_growth:+.1f}% in latest year\")\n",
    "    elif recent_growth < -5:\n",
    "        print(f\"Trend: Concerning decline of {recent_growth:+.1f}% in latest year\")\n",
    "    else:\n",
    "        print(f\"Trend: Stable performance with {recent_growth:+.1f}% change in latest year\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c731b370-60a0-4a4e-b4fd-ee84426a0329",
   "metadata": {},
   "source": [
    "### Yearly Performance Analysis - Simple and robust promotion & day analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1efb6d2-6cb0-4fd5-a317-1d3403356a6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promotion & Day of Week Analysis:\n",
      "======================================================================\n",
      "Promo  Day        Avg Customers Avg Sales    Rank  \n",
      "----------------------------------------------------------------------\n",
      "No     Mon              939     ‚Ç¨   9,709    1     \n",
      "No     Tue              837     ‚Ç¨   8,226    2     \n",
      "No     Wed              786     ‚Ç¨   7,541    3     \n",
      "No     Thu              774     ‚Ç¨   7,242    4     \n",
      "No     Fri              766     ‚Ç¨   7,169    5     \n",
      "No     Fri              717     ‚Ç¨   6,180    6     \n",
      "No     Sat              659     ‚Ç¨   5,857    7     \n",
      "No     Tue              675     ‚Ç¨   5,608    8     \n",
      "No     Mon              666     ‚Ç¨   5,568    9     \n",
      "No     Wed              648     ‚Ç¨   5,404    10    \n",
      "No     Thu              608     ‚Ç¨   5,063    11    \n",
      "No     Sun               36     ‚Ç¨     203    12    \n",
      "\n",
      "Promotion Impact by Day:\n",
      "-------------------------\n",
      "Day        No Promo     With Promo   Lift    \n",
      "---------------------------------------------\n",
      "\n",
      "Key Insights:\n",
      "---------------\n",
      "Best combination: No Promo on Mon\n",
      "Overall promo lift: +nan%\n",
      "Top sales: ‚Ç¨9,709\n"
     ]
    }
   ],
   "source": [
    "# Simple and robust promotion & day analysis\n",
    "promo_day = df_features.groupby([\"promo\", \"day\"])[[\"customers\", \"sales\"]].mean().sort_values(\"sales\", ascending=False)\n",
    "\n",
    "print(\"Promotion & Day of Week Analysis:\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Promo':<6} {'Day':<10} {'Avg Customers':<13} {'Avg Sales':<12} {'Rank':<6}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for i, ((promo, day), row) in enumerate(promo_day.iterrows(), 1):\n",
    "    promo_str = \"Yes\" if promo == 1 else \"No\"\n",
    "    print(f\"{promo_str:<6} {day:<10} {row['customers']:>9,.0f}     ‚Ç¨{row['sales']:>8,.0f}    {i:<6}\")\n",
    "\n",
    "print(f\"\\nPromotion Impact by Day:\")\n",
    "print(\"-\" * 25)\n",
    "print(f\"{'Day':<10} {'No Promo':<12} {'With Promo':<12} {'Lift':<8}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for day in sorted(df_features['day'].unique()):\n",
    "    no_promo = df_features[(df_features['promo'] == 0) & (df_features['day'] == day)]['sales'].mean()\n",
    "    with_promo = df_features[(df_features['promo'] == 1) & (df_features['day'] == day)]['sales'].mean()\n",
    "    \n",
    "    if not pd.isna(no_promo) and not pd.isna(with_promo):\n",
    "        lift = ((with_promo - no_promo) / no_promo) * 100\n",
    "        print(f\"{day:<10} ‚Ç¨{no_promo:>7,.0f}     ‚Ç¨{with_promo:>8,.0f}     {lift:>5.1f}%\")\n",
    "\n",
    "print(f\"\\nKey Insights:\")\n",
    "print(\"-\" * 15)\n",
    "best_combo = promo_day.index[0]\n",
    "overall_lift = ((df_features[df_features['promo']==1]['sales'].mean() - df_features[df_features['promo']==0]['sales'].mean()) / df_features[df_features['promo']==0]['sales'].mean()) * 100\n",
    "\n",
    "print(f\"Best combination: {'Promo' if best_combo[0]==1 else 'No Promo'} on {best_combo[1]}\")\n",
    "print(f\"Overall promo lift: {overall_lift:+.1f}%\")\n",
    "print(f\"Top sales: ‚Ç¨{promo_day.iloc[0]['sales']:,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e726ba-7b9f-4f27-8270-666a57430978",
   "metadata": {},
   "source": [
    "# ‚ú® Reusable Functions \n",
    "-----------\n",
    "It is a best practice wrap analysis impact and others into a reusable utility function so you can generate, reuse and export charts seamlessly from any part of your notebook or script. These best practices can make your code clean, powerful, and highly maintainable‚Äîwhether you're working with data cleaning, aggregation, visualization, or export routines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6574dab5-f9a9-4670-b2a3-754052bc1fe8",
   "metadata": {},
   "source": [
    "# üîß Generalized Reusable Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "997a27e3-64bd-44d3-b440-09954ede4710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_by_time(df, time_col, metrics, agg_func='mean', rename_prefix='avg', sort_by=None, ascending=False):\n",
    "    \"\"\"\n",
    "    General-purpose time-based aggregation summary.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "    - time_col: column to group by (e.g., 'year', 'month', 'dayofweek')\n",
    "    - metrics: list of metric columns to aggregate (e.g., ['sales', 'customers'])\n",
    "    - agg_func: aggregation function (default: 'mean')\n",
    "    - rename_prefix: prefix added to aggregated column names\n",
    "    - sort_by: column to sort by (e.g., 'avg_sales')\n",
    "    - ascending: sorting direction (default: descending)\n",
    "\n",
    "    Returns:\n",
    "    - Aggregated and optionally sorted DataFrame\n",
    "    \"\"\"\n",
    "    summary = (\n",
    "        df.groupby(time_col)[metrics]\n",
    "        .agg(agg_func)\n",
    "        .reset_index()\n",
    "        .rename(columns={metric: f\"{rename_prefix}_{metric}\" for metric in metrics})\n",
    "    )\n",
    "\n",
    "    if sort_by:\n",
    "        summary = summary.sort_values(by=sort_by, ascending=ascending)\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "796c2951-c5e8-496d-a141-63308ba40e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   day  avg_customers  avg_sales\n",
      "1  Mon         812.93    7797.64\n",
      "5  Tue         761.86    7005.52\n",
      "0  Fri         742.53    6703.50\n",
      "6  Wed         721.20    6536.45\n",
      "4  Thu         695.78    6216.11\n",
      "2  Sat         658.76    5856.78\n",
      "3  Sun          35.58     202.62\n"
     ]
    }
   ],
   "source": [
    "day_analysis = summarize_by_time(\n",
    "    df=df_features,\n",
    "    time_col='day',\n",
    "    metrics=['customers', 'sales'],\n",
    "    agg_func='mean',\n",
    "    rename_prefix='avg',\n",
    "    sort_by='avg_sales',\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "print(day_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbe26d45-07f0-4021-9444-4f812133e0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   month  avg_customers  avg_sales\n",
      "2    Dec         703.07    6826.61\n",
      "5    Jul         663.59    6022.61\n",
      "9    Nov         654.15    6008.11\n",
      "7    Mar         629.40    5784.58\n",
      "6    Jun         624.79    5760.96\n",
      "0    Apr         630.61    5738.87\n",
      "1    Aug         642.50    5693.02\n",
      "3    Feb         626.72    5645.25\n",
      "11   Sep         634.44    5570.25\n",
      "10   Oct         631.10    5537.04\n",
      "8    May         601.99    5489.64\n",
      "4    Jan         601.62    5465.40\n"
     ]
    }
   ],
   "source": [
    "month_analysis = summarize_by_time(\n",
    "    df=df_features,\n",
    "    time_col='month',\n",
    "    metrics=['customers', 'sales'],\n",
    "    agg_func='mean',\n",
    "    rename_prefix='avg',\n",
    "    sort_by='avg_sales',\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "print(month_analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33db20cc-e7d9-477d-a1f7-3b1536d56a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  avg_customers  avg_sales\n",
      "1  2014         643.27    5833.29\n",
      "2  2015         620.84    5832.95\n",
      "0  2013         629.04    5658.53\n"
     ]
    }
   ],
   "source": [
    "year_analysis = summarize_by_time(\n",
    "    df=df_features,\n",
    "    time_col='year',\n",
    "    metrics=['customers', 'sales'],\n",
    "    agg_func='mean',\n",
    "    rename_prefix='avg',\n",
    "    sort_by='avg_sales',\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "print(year_analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d8ddf7-b453-4d44-9359-bfe6a0701975",
   "metadata": {},
   "source": [
    "# üåü Advantages\n",
    "\n",
    "- Reusable across 'year', 'month', 'dayofweek', etc.\n",
    "\n",
    "- Easy to change aggregation type ('sum', 'median', etc.)\n",
    "\n",
    "- Consistent naming and sorting\n",
    "\n",
    "- Makes your code far more modular for dashboards or reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "589a3cf8-b3d4-4bcc-a5f7-733a781ab2fa",
   "metadata": {},
   "source": [
    "# Why Reusability Matters\n",
    "-------------------------\n",
    " - üí° Scalability: You can plug your functions into larger pipelines or production environments without rewrites.\n",
    " - üõ†Ô∏è Maintainability: A bug fix in one utility can instantly improve multiple workflows.\n",
    " - üöÄ Efficiency: Spend less time rewriting logic and more time interpreting results.\n",
    "\n",
    "# Why This Matters for Rossmann Store Sales\n",
    " - We‚Äôll likely repeat the same aggregations or visualizations across hundreds of stores.\n",
    " - Promos, holidays, and weekday patterns demand consistent filtering and analysis.\n",
    " - Modular functions help you prototype insights fast, scale across stores, and iterate smoothly.\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b33402-11dd-471a-b9c2-effe7f65283b",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4734fdac-47a4-4b96-9633-c77a9fd333be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"‚úÖ Data Ingestion and Exploratory Data Analysis completed successfully!\")\n",
    "print(f\"üóìÔ∏è Analysis Date: {bold_start}{pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}{bold_end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fb3d94-675d-4cea-bc83-2e995e1e8c94",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a578a31-6bf1-4605-8d14-c69c3df0809c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End analysis\n",
    "analysis_end = pd.Timestamp.now()\n",
    "duration = analysis_end - analysis_begin\n",
    "\n",
    "# Final summary print\n",
    "print(\"\\nüìã Analysis Summary\")\n",
    "print(f\"üü¢ Begin Date: {bold_start}{analysis_begin.strftime('%Y-%m-%d %H:%M:%S')}{bold_end}\")\n",
    "print(f\"‚úÖ End Date:   {bold_start}{analysis_end.strftime('%Y-%m-%d %H:%M:%S')}{bold_end}\")\n",
    "print(f\"‚è±Ô∏è Duration:   {bold_start}{str(duration)}{bold_end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045b4131-f856-44b5-81e8-1f72274952fa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "-------------------------\n",
    "## Project Design Rationale: Notebook Separation\n",
    "\n",
    "To promote **clarity, maintainability, and scalability** within the project, **data engineering** and **visualization tasks** are intentionally separated into distinct notebooks. This modular approach prevents the accumulation of excessive code in a single notebook, making it easier to **debug, update, and collaborate across different stages of the workflow**. By isolating data transformation logic from visual analysis, **each notebook remains focused and purpose-driven**, ultimately **enhancing the overall efficiency and readability of the project**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
