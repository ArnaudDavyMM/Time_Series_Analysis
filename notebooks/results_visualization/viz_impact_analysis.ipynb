{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56ef5700-bd71-4e44-99c4-6f17485d94f5",
   "metadata": {},
   "source": [
    "# Part 2.3: Data Visualization and Impact Analysis\n",
    "\n",
    "Modular Functions for Impact Analysis & Visualization\n",
    "\n",
    "This section provides reusable, parameterized functions for analyzing and visualizing performance metrics across temporal and categorical dimensions. Designed for flexibility and clarity, the functions support:\n",
    "\n",
    " - Dynamic grouping by time (year, month_name, day_name) or category (store, promo, etc.)\n",
    "\n",
    " - Preprocessing filters to exclude non-operational records (e.g., closed stores, zero-sales days)\n",
    "\n",
    " - Statistical summaries including mean, standard deviation, and count\n",
    "\n",
    " - Ranked insights with volatility and performance differentials\n",
    "\n",
    " - Interactive visualizations via Plotly for enhanced interpretability\n",
    "\n",
    "These tools enable scalable impact assessments and trend analyses across diverse datasets with minimal code repetition.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd832622-b6c7-4b7f-a4ef-26eeea11e6a1",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports Libraries\n",
    "-------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7ea380-c3eb-4357-bb7f-6d7bac2e04df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c364c2-8b1d-43e8-bf57-72b9249e155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Setup & Imports Libraries\n",
    "print(\"Step 1: Setup and Import Libraries started...\")\n",
    "time.sleep(1)  # Simulate processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d6c5fa-aee0-4e1f-9e59-840fdba88e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation & Processing\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "# Data Visualization\n",
    "import seaborn as sbn\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "sbn.set(rc={'figure.figsize':(14,6)})\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sbn.set_palette(\"husl\")\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format','{:.2f}'.format)\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cce5b68-7d10-4d23-aa9f-34b449a511ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Rossman Store Sales Time Series Analysis - Part 2\")\n",
    "print(\"=\"*60)\n",
    "print(\"All libraries imported successfully!\")\n",
    "print(\"Analysis Date:\", pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a328c0-6014-4359-a753-d9318c8507cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"✅ Setup and Import Liraries completed.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84aa791-e38f-4a98-b105-5ef5608c7eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Impact Analysis\n",
    "\n",
    "viz_impact_analysis_begin = pd.Timestamp.now()\n",
    "\n",
    "bold_start = '\\033[1m'\n",
    "bold_end = '\\033[0m'\n",
    "\n",
    "print(\"🔍 Viz impact Analysis Started ...\")\n",
    "print(f\"🟢 Begin Date: {bold_start}{viz_impact_analysis_begin.strftime('%Y-%m-%d %H:%M:%S')}{bold_end}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ca539c-3bf4-4d74-bc5a-0b4a77793146",
   "metadata": {},
   "source": [
    "\n",
    "## Restore the file\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24c581c-c5aa-4b97-ab72-64a64f2e9f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r df_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b18d13a-bcf7-4377-b468-a9ff17d584e8",
   "metadata": {},
   "source": [
    "### View or Display Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2f2327-6fa3-4c87-8cb8-57cca0d61d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTrain Data Preview:\")\n",
    "print(\"\\n\",df_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3b129f-cf7d-47f5-bf0b-d8f97bbb7c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data Ingestion\n",
    "print(\"Step 2: Features Engineering started...\")\n",
    "time.sleep(1)  # Simulate processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed06638-01ab-4c59-9219-05329fc793d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the original dataframe to avoid modifying it\n",
    "df_features = df_features.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f44260-86ae-44fa-8db9-b2f541cda278",
   "metadata": {},
   "source": [
    "---------------------------------------------------------\n",
    "## 🧩 Reusable Utility Functions for Analytical Workflows\n",
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1196a3f1-5a6d-48c0-b8f4-cd7f4edccd09",
   "metadata": {},
   "source": [
    "### Promotion Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147287e2-bdb1-439d-bde5-5a304876ed5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_promotion_impact(df, target_col='sales', category_col='day', width=1200, height=500):\n",
    "    \"\"\"\n",
    "    Analyze promotion impact across any category (day, month, store, etc.)\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with 'promo' column\n",
    "    - target_col: metric to analyze ('sales' or 'customers')\n",
    "    - category_col: grouping category ('day', 'month', 'store', etc.)\n",
    "    \"\"\"\n",
    "    # Filter out closed stores (e.g., sales = 0) for unbiased and fair comparison\n",
    "    df = df[df[target_col] > 0].copy()\n",
    "    \n",
    "    # Create summary data\n",
    "    summary = df.groupby([category_col, 'promo'])[target_col].mean().reset_index()\n",
    "    \n",
    "    # Visualization\n",
    "    fig = px.bar(\n",
    "        summary,\n",
    "        x=category_col,\n",
    "        y=target_col,\n",
    "        color='promo',\n",
    "        title=f'Promotion Impact: {target_col.title()} by {category_col.title()}',\n",
    "        color_discrete_map={'Promo': '#636EFA', 'No Promo': '#EF553B'},\n",
    "        barmode='group'\n",
    "    )\n",
    "    fig.update_layout(title_x=0.5, height=height, width=width)\n",
    "    fig.show()\n",
    "    \n",
    "    # Impact analysis\n",
    "    print(f\"Promotion Impact Analysis - {target_col.title()} by {category_col.title()}:\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    categories = sorted(df[category_col].unique())\n",
    "    for category in categories:\n",
    "        no_promo = df[(df[category_col] == category) & (df['promo'] == 'No Promo')][target_col].mean()\n",
    "        promo = df[(df[category_col] == category) & (df['promo'] == 'Promo')][target_col].mean()\n",
    "        \n",
    "        if not pd.isna(no_promo) and not pd.isna(promo):\n",
    "            lift = ((promo - no_promo) / no_promo) * 100\n",
    "            currency = \"€\" if target_col == 'sales' else \"\"\n",
    "            print(f\"{str(category):12}: No Promo {currency}{no_promo:6,.0f} | Promo {currency}{promo:6,.0f} | Lift {lift:+5.1f}%\")\n",
    "    \n",
    "    # Overall summary\n",
    "    overall_no_promo = df[df['promo'] == 'No Promo'][target_col].mean()\n",
    "    overall_promo = df[df['promo'] == 'Promo'][target_col].mean()\n",
    "    overall_lift = ((overall_promo - overall_no_promo) / overall_no_promo) * 100\n",
    "    currency = \"€\" if target_col == 'sales' else \"\"\n",
    "    \n",
    "    print(f\"\\nOverall Impact:\")\n",
    "    print(f\"Average lift from promotions: {overall_lift:+.1f}%\")\n",
    "    print(f\"Additional revenue per day: {currency}{overall_promo - overall_no_promo:,.0f}\")\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce795c39-289e-49d8-840f-0d8a76901490",
   "metadata": {},
   "source": [
    "### Top performer Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926c9fc7-35b1-478c-a669-838f683f0fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_top_performers(df, group_col='store', target_col='sales', top_n=10, width=1200, height=500):\n",
    "    \"\"\"\n",
    "    Analyze top performing entities (stores, days, months, etc.)\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame \n",
    "    - group_col: column to group by ('store', 'day', 'month', etc.)\n",
    "    - target_col: metric to analyze ('sales' or 'customers')  \n",
    "    - top_n: number of top performers to show\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter out closed stores (e.g., sales = 0) for unbiased and fair comparison\n",
    "    df = df[df[target_col] > 0].copy()\n",
    "    \n",
    "    # Calculate averages and get top performers\n",
    "    group_avg = df.groupby(group_col)[target_col].mean()\n",
    "    top_performers = group_avg.nlargest(top_n)\n",
    "    \n",
    "    # Visualization\n",
    "    fig = px.bar(\n",
    "        x=top_performers.index.astype(str),\n",
    "        y=top_performers.values,\n",
    "        title=f'Top {top_n} {group_col.title()} by Average {target_col.title()}',\n",
    "        labels={'x': group_col.title(), 'y': f'Average {target_col.title()}'}\n",
    "    )\n",
    "    fig.update_layout(title_x=0.5, height=height, width=width)\n",
    "    fig.show()\n",
    "    \n",
    "    # Performance analysis\n",
    "    print(f\"Top {top_n} {group_col.title()} Performance Analysis:\")\n",
    "    print(\"=\" * 55)\n",
    "    print(f\"{'Rank':<4} {group_col.title():<10} {'Average':<15} {'% of #1':<10}\")\n",
    "    print(\"-\" * 55)\n",
    "    \n",
    "    for i, (entity, avg_value) in enumerate(top_performers.items(), 1):\n",
    "        pct_of_top = (avg_value / top_performers.iloc[0]) * 100\n",
    "        currency = \"€\" if target_col == 'sales' else \"\"\n",
    "        print(f\"{i:<4} {str(entity):<10} {currency}{avg_value:>9,.0f}     {pct_of_top:>6.1f}%\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    total_entities = len(group_avg)\n",
    "    top_avg = top_performers.mean()\n",
    "    overall_avg = group_avg.mean()\n",
    "    performance_gap = ((top_avg - overall_avg) / overall_avg) * 100\n",
    "    \n",
    "    print(f\"\\nSummary Statistics:\")\n",
    "    print(f\"Total {group_col}s analyzed: {total_entities:,}\")\n",
    "    print(f\"Top {top_n} average: {currency}{top_avg:,.0f}\")\n",
    "    print(f\"Overall average: {currency}{overall_avg:,.0f}\")\n",
    "    print(f\"Top {top_n} outperform by: {performance_gap:.1f}%\")\n",
    "    \n",
    "    return top_performers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d3f827-3a6f-4477-94b8-8ac2b58be0bb",
   "metadata": {},
   "source": [
    "### Temporal Trends Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b64c573-eebb-46ff-8c6c-5f5a7d6f02f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_temporal_trends(df, time_col='month', target_col='sales', width=1200, height=500):\n",
    "    \"\"\"\n",
    "    Analyze trends over time periods (month_name, day_name, year, etc.)\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame\n",
    "    - time_col: time dimension ('month_name', 'day_name', 'year', etc.)\n",
    "    - target_col: metric to analyze ('sales' or 'customers')\n",
    "    \"\"\"\n",
    "    # Filter out closed stores (e.g., sales = 0) for unbiased and fair comparison\n",
    "    df = df[df[target_col] > 0].copy()\n",
    "\n",
    "   # Calculate averages by time period\n",
    "    time_stats = df.groupby(time_col).agg({\n",
    "        target_col: ['mean', 'std', 'count']\n",
    "    }).round(0)\n",
    "    \n",
    "    time_stats.columns = ['avg', 'std', 'count']\n",
    "    time_stats = time_stats.reset_index().sort_values('avg', ascending=False)\n",
    "    \n",
    "    # Visualization\n",
    "    fig = px.bar(\n",
    "        time_stats,\n",
    "        x=time_col,\n",
    "        y='avg',\n",
    "        title=f'{target_col.title()} Performance by {time_col.title()}',\n",
    "        color='avg',\n",
    "        color_continuous_scale='viridis'\n",
    "    )\n",
    "    fig.update_layout(title_x=0.5, height=height, width=width)\n",
    "    fig.show()\n",
    "    \n",
    "    # Trend analysis\n",
    "    print(f\"{time_col.title()} Performance Analysis:\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"{'Rank':<4} {time_col.title():<12} {'Average':<15} {'Std Dev':<10} {'Count':<8}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for i, row in time_stats.iterrows():\n",
    "        currency = \"€\" if target_col == 'sales' else \"\"\n",
    "        print(f\"{i+1:<4} {str(row[time_col]):<12} {currency}{row['avg']:>9,.0f}     {currency}{row['std']:>6,.0f}   {row['count']:>6,.0f}\")\n",
    "    \n",
    "    # Key insights\n",
    "    best_period = time_stats.iloc[0][time_col]\n",
    "    worst_period = time_stats.iloc[-1][time_col]\n",
    "    best_value = time_stats.iloc[0]['avg']\n",
    "    worst_value = time_stats.iloc[-1]['avg']\n",
    "    volatility = ((best_value - worst_value) / time_stats['avg'].mean()) * 100\n",
    "    \n",
    "    currency = \"€\" if target_col == 'sales' else \"\"\n",
    "    print(f\"\\nKey Insights:\")\n",
    "    print(f\"Best {time_col}: {best_period} ({currency}{best_value:,.0f})\")\n",
    "    print(f\"Worst {time_col}: {worst_period} ({currency}{worst_value:,.0f})\")\n",
    "    print(f\"Performance range: {currency}{best_value - worst_value:,.0f}\")\n",
    "    print(f\"Volatility: {volatility:.1f}%\")\n",
    "    \n",
    "    return time_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5af2ea2-f699-4fb8-b549-212abdea6b3d",
   "metadata": {},
   "source": [
    "### State Holiday Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f244e10-abb3-48e1-9ead-cdfb90555c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_stateholiday_impact(df, target_col ='sales', category_col ='day', width =1200, height =500):\n",
    "    \"\"\"\n",
    "    Analyze the impact of state holidays across a specified category (e.g., day, month, store).\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame with 'stateholiday' column already mapped to labels\n",
    "    - target_col: metric to analyze ('sales' or 'customers')\n",
    "    - category_col: grouping category ('day', 'month', 'store', etc.)\n",
    "    \"\"\"\n",
    "    # Filter out closed stores (e.g., sales = 0) for unbiased and fair comparison\n",
    "    df_open = df[df[target_col] > 0].copy()\n",
    "    \n",
    "    # Create summary data\n",
    "    summary = df_open.groupby([category_col, 'stateholiday'])[target_col].mean().reset_index()\n",
    "    \n",
    "    # Visualization\n",
    "    fig = px.bar(\n",
    "        summary,\n",
    "        x =category_col,\n",
    "        y =target_col,\n",
    "        color ='stateholiday',\n",
    "        title =f'State Holiday Impact: {target_col.title()} by {category_col.title()}',\n",
    "        barmode ='group'\n",
    "    )\n",
    "    fig.update_layout(title_x =0.5, height =height, width =width)\n",
    "    fig.show()\n",
    "    \n",
    "    # Impact analysis\n",
    "    print(f\"State Holiday Impact Analysis - {target_col.title()} by {category_col.title()}:\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    # Get regular day baseline\n",
    "    regular_avg = df_open[df_open['stateholiday'] == 'Normal Day'][target_col].mean()\n",
    "    \n",
    "    # Overall holiday impact\n",
    "    print(\"Overall Holiday Impact:\")\n",
    "    print(\"-\" * 25)\n",
    "    for holiday_label in ['Public', 'Easter', 'Christmas']:\n",
    "        if holiday_label in df['stateholiday'].values:\n",
    "            holiday_avg = df_open[df_open['stateholiday'] == holiday_label][target_col].mean()\n",
    "            if not pd.isna(holiday_avg):\n",
    "                impact = ((holiday_avg - regular_avg) / regular_avg) * 100\n",
    "                currency = \"€\" if target_col == 'sales' else \"\"\n",
    "                print(f\"{holiday_label:15}: {currency}{holiday_avg:6,.0f} ({impact:+5.1f}% vs regular)\")\n",
    "    \n",
    "    print(f\"Regular Days: €{regular_avg:6,.0f} (baseline)\")\n",
    "    \n",
    "    # Category-wise analysis\n",
    "    print(f\"\\nHoliday Impact by {category_col.title()}:\")\n",
    "    print(\"-\" * 35)\n",
    "    \n",
    "    categories = sorted(df[category_col].unique())\n",
    "    for category in categories:\n",
    "        regular = df_open[(df_open[category_col] == category) & (df_open['stateholiday'] == 'Normal Day')][target_col].mean()\n",
    "        holiday = df_open[(df_open[category_col] == category) & (df_open['stateholiday'] != 'Normal Day')][target_col].mean()\n",
    "        \n",
    "        if not pd.isna(regular):\n",
    "            currency = \"€\" if target_col == 'sales' else \"\"\n",
    "            if not pd.isna(holiday):\n",
    "                impact = ((holiday - regular) / regular) * 100\n",
    "                print(f\"{str(category):12}: Regular {currency}{regular:6,.0f} | Holiday {currency}{holiday:6,.0f} | Impact {impact:+5.1f}%\")\n",
    "            else:\n",
    "                print(f\"{str(category):12}: Regular {currency}{regular:6,.0f} | No holiday data\")\n",
    "    \n",
    "    # Store closure analysis\n",
    "    total_records = len(df)\n",
    "    closed_stores = len(df[df[target_col] == 0])\n",
    "    holiday_closures = len(df[(df['stateholiday'] != 'Normal Day') & (df[target_col] == 0)])\n",
    "    regular_closures = len(df[(df['stateholiday'] == 'Normal Day') & (df[target_col] == 0)])\n",
    "    \n",
    "    print(f\"\\nStore Operations Impact:\")\n",
    "    print(\"-\" * 25)\n",
    "    print(f\"Total store closures: {closed_stores:,} ({(closed_stores/total_records)*100:.1f}%)\")\n",
    "    print(f\"Holiday closures: {holiday_closures:,}\")\n",
    "    print(f\"Regular closures: {regular_closures:,}\")\n",
    "    \n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c12c461-816f-4044-ada3-6e0af18d215a",
   "metadata": {},
   "source": [
    "### RUNNING TOP 4 IMPORTANT ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a325c444-1142-4836-bbef-2b3eb3e6f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Assuming df_features is your dataset\n",
    "    \n",
    "    print(\"=== RUNNING TOP 4 MOST IMPORTANT ANALYSES ===\\n\")\n",
    "    \n",
    "    # 1. Promotion Impact Analysis\n",
    "    print(\"1. PROMOTION IMPACT ANALYSIS\")\n",
    "    print(\"-\" * 40)\n",
    "    promo_results = analyze_promotion_impact(df_features, target_col='sales', category_col='day')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # 2. State Holiday Impact Analysis\n",
    "    print(\"2. STATE HOLIDAY IMPACT ANALYSIS\")\n",
    "    print(\"-\" * 40)\n",
    "    holiday_results = analyze_stateholiday_impact(df_features, target_col='sales', category_col='day')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # 3. Top Store Performance Analysis  \n",
    "    print(\"3. TOP STORE PERFORMANCE ANALYSIS\")\n",
    "    print(\"-\" * 40)\n",
    "    store_results = analyze_top_performers(df_features, group_col='store', target_col='sales', top_n=10)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # 4. Temporal Trends Analysis\n",
    "    print(\"4. TEMPORAL TRENDS ANALYSIS\")\n",
    "    print(\"-\" * 40)\n",
    "    trend_results = analyze_temporal_trends(df_features, time_col='month', target_col='sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f889aa39-4a2b-40a5-a6f4-69879be4b609",
   "metadata": {},
   "source": [
    "### Top 5 performing days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef733831-92f7-4ba6-bbea-7ee309f0aaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 5 performing days\n",
    "analyze_top_performers(df_features, 'day', 'sales', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a3ed6c-fd45-4093-9799-6faaac447784",
   "metadata": {},
   "source": [
    "### Yearly sales trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6c4929-a609-449d-9888-3ca39f18ea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yearly sales trends\n",
    "analyze_temporal_trends(df_features, 'year', 'sales')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155dff46-decb-423f-ae42-8b093721bc45",
   "metadata": {},
   "source": [
    "### Promotion impact on customers by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe83088-660d-436c-8995-fc5bd143d904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Promotion impact on customers by month\n",
    "analyze_promotion_impact(df_features, 'customers', 'month')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7195c9db-b835-4ada-839f-ab48c4c3f930",
   "metadata": {},
   "source": [
    "### # Holiday impact on customers by month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb619d2-b091-4a47-b724-de316c5fde58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Holiday impact on customers by month\n",
    "analyze_stateholiday_impact(df_features, 'customers', 'month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0eae31-e0e7-40a7-ad02-9d3f838e6c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"✅ Data Visualization Impact Analysis completed.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375c5497-d09a-4f81-86c6-5c8532463a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"✅ Features Engineering and Data Visualization (I) completed successfully!\")\n",
    "print(f\"🗓️ Analysis Date: {bold_start}{pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}{bold_end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7062c38-11fa-4ec6-b262-103ad5895915",
   "metadata": {},
   "source": [
    "----------------------------------------\n",
    "# 🌟 Advantages\n",
    "\n",
    "- Reusable across 'year', 'month', 'dayofweek', etc.\n",
    "\n",
    "- Easy to change aggregation type ('sum', 'median', etc.)\n",
    "\n",
    "- Consistent naming and sorting\n",
    "\n",
    "- Makes your code far more modular for dashboards or reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcea956-0111-4a31-a4e5-029c2ab21058",
   "metadata": {},
   "source": [
    "# Why Reusability Matters\n",
    "-------------------------\n",
    " - 💡 Scalability: You can plug your functions into larger pipelines or production environments without rewrites.\n",
    " - 🛠️ Maintainability: A bug fix in one utility can instantly improve multiple workflows.\n",
    " - 🚀 Efficiency: Spend less time rewriting logic and more time interpreting results.\n",
    "\n",
    "# Why This Matters for Rossmann Store Sales\n",
    " - We’ll likely repeat the same aggregations or visualizations across hundreds of stores.\n",
    " - Promos, holidays, and weekday patterns demand consistent filtering and analysis.\n",
    " - Modular functions help you prototype insights fast, scale across stores, and iterate smoothly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3915ad3-a6b3-4eb6-bb84-8b7ff45e803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# End analysis\n",
    "viz_impact_analysis_end = pd.Timestamp.now()\n",
    "duration = viz_impact_analysis_end - viz_impact_analysis_begin\n",
    "\n",
    "# Final summary print\n",
    "print(\"\\n📋 Features Engineering && Data Viz Summary\")\n",
    "print(f\"🟢 Begin Date: {bold_start}{viz_impact_analysis_begin.strftime('%Y-%m-%d %H:%M:%S')}{bold_end}\")\n",
    "print(f\"✅ End Date:   {bold_start}{viz_impact_analysis_end.strftime('%Y-%m-%d %H:%M:%S')}{bold_end}\")\n",
    "print(f\"⏱️ Duration:   {bold_start}{str(duration)}{bold_end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784f684d-a551-4071-ac54-fbd1ee1533be",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "## Project Design Rationale: Notebook Separation\n",
    "\n",
    "To promote **clarity, maintainability, and scalability** within the project, **data engineering** and **visualization tasks** are intentionally separated into distinct notebooks. This modular approach prevents the accumulation of excessive code in a single notebook, making it easier to **debug, update, and collaborate across different stages of the workflow**. By isolating data transformation logic from visual analysis, **each notebook remains focused and purpose-driven**, ultimately **enhancing the overall efficiency and readability of the project**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
