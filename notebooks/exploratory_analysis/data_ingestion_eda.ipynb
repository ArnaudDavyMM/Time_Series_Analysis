{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "226b3337-c185-4bb0-adad-9ec9f641d3e6",
   "metadata": {},
   "source": [
    "## Part 1: Data Ingestion and Exploratory Data Analysis (EDA)\n",
    "-------------------------------------------------------------\n",
    "\n",
    "In this section, we will focus on **ingesting** the Rossmann Store Sales dataset and conducting a comprehensive **Exploratory Data Analysis (EDA)** prior to applying time series modeling and forecasting techniques. The workflow will proceed through the following steps:\n",
    "\n",
    "1. **Import Libraries and Dependencies:** Load all necessary Python libraries and packages required for data manipulation, visualization, and analysis.\n",
    "\n",
    "1. **Data Ingestion:** Load the Rossmann Store Sales dataset into the working environment for analysis.\n",
    "\n",
    "3. **Exploratory Data Analysis (EDA):** Perform a detailed examination of the dataset to understand its structure and key characteristics:\n",
    "\n",
    "   - **Inspect dataset metadata**: data types, number of observations (rows), and variables (columns)\n",
    "\n",
    "    - **Identify and quantify missing values**\n",
    "\n",
    "    - **Detect and handle duplicate records**\n",
    "\n",
    "    - **Generate summary statistics** (mean, median, standard deviation, etc.)\n",
    "\n",
    "    - **Analyze individual features and their distributions**\n",
    "\n",
    "    - **Apply feature engineering techniques to enhance model readiness**\n",
    "\n",
    "    - **Evaluate feature correlations to identify relationships**\n",
    "\n",
    "    - **Visualize data using appropriate plots and charts**\n",
    "\n",
    "    - **Conduct deeper analysis to uncover trends, patterns, and seasonality within the time series**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd832622-b6c7-4b7f-a4ef-26eeea11e6a1",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports Libraries\n",
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21a4ece7-9e78-4878-b52b-28605ad85ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4563f70e-b121-4e17-8522-e90be7726f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Setup and Import Libraries in progress...\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Data Ingestion\n",
    "print(\"Step 1: Setup and Import Libraries in progress...\")\n",
    "time.sleep(1)  # Simulate processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75d6c5fa-aee0-4e1f-9e59-840fdba88e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Rossman Store Sales Time Series Analysis - Part 1\n",
      "============================================================\n",
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Data Manipulation & Processing\n",
    "import os\n",
    "import holidays\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import scipy.stats as stats\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format','{:.2f}'.format)\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Rossman Store Sales Time Series Analysis - Part 1\")\n",
    "print(\"=\"*60)\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28356173-747b-4d1f-8398-e5ccca45e36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup and Import Liraries completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"‚úÖ Setup and Import Liraries completed.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cce5b68-7d10-4d23-aa9f-34b449a511ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Analysis Started\n",
      "üü¢ Begin Date: \u001b[1m2025-08-13 21:09:59\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start analysis\n",
    "\n",
    "analysis_begin = pd.Timestamp.now()\n",
    "\n",
    "bold_start = '\\033[1m'\n",
    "bold_end = '\\033[0m'\n",
    "\n",
    "print(\"üîç Analysis Started\")\n",
    "print(f\"üü¢ Begin Date: {bold_start}{analysis_begin.strftime('%Y-%m-%d %H:%M:%S')}{bold_end}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ca539c-3bf4-4d74-bc5a-0b4a77793146",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Data Ingestion\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "705d6ee5-e88f-43e5-89fd-6e454bfb56d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Data Ingestion in progress...\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Data Ingestion\n",
    "print(\"Step 2: Data Ingestion in progress...\")\n",
    "time.sleep(1)  # Simulate processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e24c581c-c5aa-4b97-ab72-64a64f2e9f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for files in: /home/mukwa/Desktop/Time_Series_Analysis/data/raw\n",
      "\n",
      "Train file exists: True\n",
      "Test file exists: True\n",
      "\n",
      "Files loaded successfully!\n",
      "\n",
      "Train data shape: (982644, 9)\n",
      "Test data shape: (34565, 9)\n",
      "\n",
      "There are : 982644 Rows and 9 Columns in training data\n",
      "There are : 34565 Rows and 9 Columns in testing data\n"
     ]
    }
   ],
   "source": [
    "# Use absolute path to avoid pwd issues\n",
    "base_path = Path.home() /\"Desktop\"/\"Time_Series_Analysis\"/\"data\"/\"raw\"\n",
    "train_path = base_path /\"Retail_train_data.csv\"\n",
    "test_path = base_path / \"Retail_test_data.csv\"\n",
    "\n",
    "# Check if files exist\n",
    "print(f\"Looking for files in: {base_path}\\n\")\n",
    "print(f\"Train file exists: {train_path.exists()}\")\n",
    "print(f\"Test file exists: {test_path.exists()}\")\n",
    "\n",
    "if train_path.exists() and test_path.exists():\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    print(\"\\nFiles loaded successfully!\\n\")\n",
    "    print(f\"Train data shape: {train_df.shape}\")\n",
    "    print(f\"Test data shape: {test_df.shape}\\n\")\n",
    "    print('There are : %s Rows and %s Columns in training data' % (str(train_df.shape[0]) ,str(train_df.shape[1])))\n",
    "    print('There are : %s Rows and %s Columns in testing data' % (str(test_df.shape[0]) ,str(test_df.shape[1])))\n",
    "else:\n",
    "    print(\"Files not found. Please check the file paths and names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fe1b626-5584-493e-89b2-4b13da6daec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data Ingestion completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"‚úÖ Data Ingestion completed.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5988d899-2b50-45c1-82de-8e6e2c196546",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis (EDA)\n",
    "## 3.1. Basic Inspection\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48fb8f22-7014-4523-8a1b-7a6338f396a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Step 3: Exploratory Data Analysis in progress...\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Exploratory Data Analysis (EDA)\n",
    "print(\"üìä Step 3: Exploratory Data Analysis in progress...\")\n",
    "time.sleep(1)  # Simulate processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4157b20d-8631-44d4-9512-0f305dbd184e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 982644 entries, 0 to 982643\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   store          982644 non-null  int64 \n",
      " 1   dayofweek      982644 non-null  int64 \n",
      " 2   date           982644 non-null  object\n",
      " 3   sales          982644 non-null  int64 \n",
      " 4   customers      982644 non-null  int64 \n",
      " 5   open           982644 non-null  int64 \n",
      " 6   promo          982644 non-null  int64 \n",
      " 7   stateholiday   982644 non-null  object\n",
      " 8   schoolholiday  982644 non-null  int64 \n",
      "dtypes: int64(7), object(2)\n",
      "memory usage: 67.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.columns = train_df.columns.str.lower()\n",
    "test_df.columns = test_df.columns.str.lower()\n",
    "\n",
    "# --- BASIC INFO AND DUPLICATES ---\n",
    "print(\"DataFrame Info:\")\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b18d13a-bcf7-4377-b468-a9ff17d584e8",
   "metadata": {},
   "source": [
    "## View or Display Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c2f2327-6fa3-4c87-8cb8-57cca0d61d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Data Preview:\n",
      "   store  dayofweek        date  sales  customers  open  promo stateholiday  schoolholiday\n",
      "0      1          2  2015-06-30   5735        568     1      1            0              0\n",
      "1      2          2  2015-06-30   9863        877     1      1            0              0\n",
      "2      3          2  2015-06-30  13261       1072     1      1            0              1\n",
      "3      4          2  2015-06-30  13106       1488     1      1            0              0\n",
      "4      5          2  2015-06-30   6635        645     1      1            0              0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain Data Preview:\")\n",
    "print(train_df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef996b4e-34d3-421d-a3a5-7c04ff033f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2013-01-01', '2015-06-30')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['date'].min(), train_df['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ada5a0bc-0ca6-450f-b03c-79e1d74795c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Data Preview:\n",
      "        store  dayofweek        date  sales  customers  open  promo stateholiday  schoolholiday\n",
      "982643   1115          2  2013-01-01      0          0     0      0            a              1\n",
      "981908    379          2  2013-01-01      0          0     0      0            a              1\n",
      "981907    378          2  2013-01-01      0          0     0      0            a              1\n",
      "981906    377          2  2013-01-01      0          0     0      0            a              1\n",
      "981905    376          2  2013-01-01      0          0     0      0            a              1 \n",
      "\n",
      "\n",
      "Test Data Preview:\n",
      "       store  dayofweek        date  sales  customers  open  promo  stateholiday  schoolholiday\n",
      "34560   1111          3  2015-07-01   3701        351     1      1             0              1\n",
      "34561   1112          3  2015-07-01  10620        716     1      1             0              1\n",
      "34562   1113          3  2015-07-01   8222        770     1      1             0              0\n",
      "34563   1114          3  2015-07-01  27071       3788     1      1             0              0\n",
      "34564   1115          3  2015-07-01   7701        447     1      1             0              0\n"
     ]
    }
   ],
   "source": [
    "train_df.sort_values('date', inplace =True, ascending =True)\n",
    "\n",
    "print(\"\\nTrain Data Preview:\")\n",
    "print(train_df.head(), \"\\n\")\n",
    "print(\"\\nTest Data Preview:\")\n",
    "print(test_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "162ffbfb-ae1a-4ef3-ac43-57f4f1aa0897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Data Preview:\n",
      "        store  dayofweek        date  sales  customers  open  promo stateholiday  schoolholiday\n",
      "982643   1115          2  2013-01-01      0          0     0      0            a              1\n",
      "981908    379          2  2013-01-01      0          0     0      0            a              1\n",
      "981907    378          2  2013-01-01      0          0     0      0            a              1\n",
      "981906    377          2  2013-01-01      0          0     0      0            a              1\n",
      "981905    376          2  2013-01-01      0          0     0      0            a              1 \n",
      "\n",
      "\n",
      "Test Data Preview:\n",
      "     store  dayofweek        date  sales  customers  open  promo  stateholiday  schoolholiday\n",
      "745    746          5  2015-07-31   9082        638     1      1             0              1\n",
      "746    747          5  2015-07-31  10708        826     1      1             0              1\n",
      "747    748          5  2015-07-31   7481        578     1      1             0              1\n",
      "741    742          5  2015-07-31  10460       1016     1      1             0              1\n",
      "0        1          5  2015-07-31   5263        555     1      1             0              1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_df.sort_values('date', inplace =True, ascending =True)\n",
    "\n",
    "print(\"\\nTest Data Preview:\")\n",
    "print(train_df.head(), \"\\n\")\n",
    "print(\"\\nTest Data Preview:\")\n",
    "print(test_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d02c3b83-bb1c-41e8-95af-6f51d470adf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values per Column:\n",
      "store            0\n",
      "dayofweek        0\n",
      "date             0\n",
      "sales            0\n",
      "customers        0\n",
      "open             0\n",
      "promo            0\n",
      "stateholiday     0\n",
      "schoolholiday    0\n",
      "dtype: int64\n",
      "\n",
      "Number of duplicated rows: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing Values per Column:\")\n",
    "print(train_df.isna().sum())\n",
    "print('\\nNumber of duplicated rows:', train_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73df65c-335a-4a11-9fa5-c5fb83df4be4",
   "metadata": {},
   "source": [
    "## 3.2 Summary Statistics\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a6e0c87-14b2-4890-a2db-9a6d5b28ae97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Statistics:\n",
      "          store  dayofweek     sales  customers      open     promo  schoolholiday\n",
      "count 982644.00  982644.00 982644.00  982644.00 982644.00 982644.00      982644.00\n",
      "mean     558.44       4.00   5760.84     632.77      0.83      0.38           0.17\n",
      "std      321.91       2.00   3857.57     465.40      0.38      0.49           0.38\n",
      "min        1.00       1.00      0.00       0.00      0.00      0.00           0.00\n",
      "25%      280.00       2.00   3705.00     403.00      1.00      0.00           0.00\n",
      "50%      558.00       4.00   5731.00     609.00      1.00      0.00           0.00\n",
      "75%      838.00       6.00   7847.00     838.00      1.00      1.00           0.00\n",
      "max     1115.00       7.00  41551.00    7388.00      1.00      1.00           1.00\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSummary Statistics:\")\n",
    "print(train_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c0067e-5ac7-479f-8604-868b77d5da11",
   "metadata": {},
   "source": [
    "----------------------------------------------------\n",
    "\n",
    "### This my previous version of Statistical Analysis\n",
    "\n",
    "1. **Store-Level Insights :**\n",
    " *  Store IDs range from **1 to 1115**, suggesting over a thousand **(1115)** unique stores in the dataset.\n",
    " *  The distribution of store IDs **(mean ‚âà 558, std ‚âà 322)** implies a relatively even spread across stores, but some clustering may exist around the median (558).\n",
    "   \n",
    "2. **Temporal Patterns :**\n",
    " *  DayOfWeek ranges from **1 to 7**, with a mean of **~4.00**‚Äîindicating a fairly uniform distribution of entries across all days.\n",
    " *  Could be interesting to examine how sales and customers vary by weekday, especially near the weekend peak **(e.g., Friday/Saturday)**.\n",
    "\n",
    "3. **Sales & Customer Traffic:**\n",
    " *  Average daily sales per entry: **5760.84** with a very wide spread **(std ‚âà 3857.57)**, and a maximum sale day of **$41,551**‚Äîa strong hint at major spikes for certain stores or events.\n",
    " *  Customer count averages **~633** per day, also with high variability **(max nearly 7,400)**, pointing to inconsistent foot traffic across locations and days.\n",
    " *  Zero-sales and zero-customer days are quite high **(‚âà 17% of records)**. These likely correspond to closed stores or unusual business days and should be accounted for in any forecasting or revenue analysis.\n",
    " *   The mean for sales is **5760.843 and the median 5731.00**, suggesting the **sales distribution is right skewed**\n",
    "\n",
    "5. **Store Availability:**\n",
    " *  Open flag mean is **0.829**, meaning stores are open roughly **83%** of the time.\n",
    "\n",
    "6. **Promotional Impact**\n",
    " *  38% of entries have active promotions, and sales/customer variability suggests these promotions could have significant but uneven impact.\n",
    " *  Worth analyzing sales uplift due to **Promo = 1 compared to Promo = 0**.\n",
    "\n",
    "7. **School Holidays**\n",
    " *  **Only 17.2%** of entries fall on a school holiday, suggesting that sales are not high on School Holidays\n",
    " *  This feature may influence customer counts, especially for stores near schools or those that rely on family shoppers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac88e20-31cf-42e1-8ade-5f0b8ffc841b",
   "metadata": {},
   "source": [
    "--------------------------------------------------------\n",
    "### This my current (updated) version of Statistical Analysis\n",
    "\n",
    "Looking at these retail summary statistics, several key insights emerge about this dataset's business patterns and data quality:\n",
    "\n",
    "**Business Operations Pattern**\n",
    "The data reveals a clear weekly rhythm with stores typically open **5-6 days per week (82.9% open rate)**. The day-of-week distribution **(mean ~4.0, std 2.0)** suggests relatively even coverage across the week, though weekends likely see different patterns given the standard deviation.\n",
    "\n",
    "**Sales Performance Distribution**\n",
    "Daily sales **average ‚Ç¨5,761** with substantial variation **(std ‚Ç¨3,858)**, indicating significant differences between high and low-performing periods. The distribution appears right-skewed, as the **median (‚Ç¨5,731)** sits below the **75th percentile (‚Ç¨7,847)**, while the **maximum of ‚Ç¨41,551** represents exceptional peak performance days.\n",
    "\n",
    "**Customer traffic** follows a similar pattern, **averaging 633 customers per day** with the same **right-skewed distribution**. The sales-to-customer ratio of approximately **‚Ç¨9.11 per customer** suggests this could be a grocery or everyday retail environment.\n",
    "\n",
    "**Promotional and Seasonal Effects**\n",
    "Promotions run on **38%** of operating days, suggesting strategic rather than constant promotional activity. School holidays affect only **17.2%** of the dataset, indicating this captures mostly regular school periods with some holiday shopping included.\n",
    "\n",
    "**Data Quality Concerns**\n",
    "The most striking finding is that **168,494 rows (17.1%)** show zero sales, with an almost identical number showing zero customers **(168,492)**. This near-perfect correlation suggests these represent genuine store closures rather than data collection errors. These closed days significantly impact the overall averages and explain why the \"Open\" variable shows **82.9% rather than 100%**.\n",
    "\n",
    "**Strategic Implications**\n",
    "The wide performance range and promotional frequency suggest opportunities for optimizing both timing and targeting of marketing efforts. The substantial day-to-day variation in both sales and customer counts indicates strong external factors **(likely day-of-week effects, promotions, and seasonal patterns)** that could be leveraged for better forecasting and inventory management.\n",
    "\n",
    "This appears to be a comprehensive retail dataset suitable for time series analysis, promotional effectiveness studies, and customer behavior modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45247aa9-f293-427d-adae-d03d3818cb50",
   "metadata": {},
   "source": [
    "## 3.3 Variables Analysis\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994dda02-d381-4b67-9ff9-218d51511fad",
   "metadata": {},
   "source": [
    "#### 1. Suspicious Days (Quality Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa8f6250-3fe6-4d7f-b64f-30cb60f26e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suspicious days with sales but no customers: 0\n"
     ]
    }
   ],
   "source": [
    "# Days with zero customers and non-zero sales (quality check)\n",
    "odd_days = train_df[(train_df[\"customers\"] == 0) & (train_df[\"sales\"] > 0)]\n",
    "print(f\"Suspicious days with sales but no customers: {odd_days.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83017689-aad1-4109-80bc-3a3fa25618f2",
   "metadata": {},
   "source": [
    "#### 2. Unique days of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6a0d2f1-b11f-453f-9062-b4a6c6e5669d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique days of the week in the dataset: [1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "unique_days = train_df['dayofweek'].sort_values().unique()\n",
    "print(f\"Unique days of the week in the dataset: {unique_days}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e025485-2e4b-46c3-b930-6336926a488a",
   "metadata": {},
   "source": [
    "#### 3. Unique State Holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5704f52-6f19-4baa-82f6-c44eca943653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique State holiday in the dataset: ['a' '0' 'b' 'c' 0]\n"
     ]
    }
   ],
   "source": [
    "unique_stateholiday = train_df['stateholiday'].unique()\n",
    "print(f\"Unique State holiday in the dataset: {unique_stateholiday}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f21f10af-38df-421d-80bd-dca2738927e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Holiday Value Counts:\n",
      "stateholiday\n",
      "0    951594\n",
      "a     20260\n",
      "b      6690\n",
      "c      4100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# -- That mix of '0' (string) and 0 (integer) in your array means the column has inconsistent data types ‚Äî which can definitely mess up mappings and analysis.\n",
    "\n",
    "# -- Clean the Data Types\n",
    "train_df['stateholiday'] = train_df['stateholiday'].astype(str)\n",
    "\n",
    "# --- Sorted Output with counts\n",
    "print(\"State Holiday Value Counts:\")\n",
    "print(train_df['stateholiday'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870e7454-0f13-4ab8-8ced-8a3184e5fe39",
   "metadata": {},
   "source": [
    "-------------------------------------------------------\n",
    "### State Holidays namming convention\n",
    "\n",
    " .  **a** stands for **Public Holiday**\n",
    "\n",
    " .  **b** stands for **Easter Holiday**\n",
    "\n",
    " .  **c** stands for **Christmas Holiday**\n",
    "\n",
    " .  **0** or None means **Normal Day**\n",
    "\n",
    "These codes were defined by the dataset creators to simplify **holiday categorization across German states**. So when we preprocess the data, we map those codes to their actual meanings to make analysis and visualization more intuitive.\n",
    "\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca6a27a-0c32-4ca8-a851-49e24028f13c",
   "metadata": {},
   "source": [
    "#### 4. Closed Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4c9da22-8b7a-492d-bf70-7b5294d3782c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of times stores were closed: \u001b[1m168440\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "closed_count = (train_df['open'] == 0).sum()\n",
    "print(f\"\\nTotal number of times stores were closed: {bold_start}{closed_count}{bold_end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ef3703-7131-4d6c-899d-28b6014b1afd",
   "metadata": {},
   "source": [
    "#### 5. Opened_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01bafac5-9162-48f6-b8dd-6adca19e3b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of times stores were opened: \u001b[1m814204\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "opened_count = (train_df['open'] == 1).sum()\n",
    "print(f\"\\nTotal number of times stores were opened: {bold_start}{opened_count}{bold_end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f2c7b7-90d6-4356-bbbd-acb1edb345b1",
   "metadata": {},
   "source": [
    "#### 6. Compare Open vs Closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ea6be60-c7c9-40c7-bdb1-c7b9559d50f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened: \u001b[1m814204\u001b[0m times (\u001b[1m82.86%)\u001b[0m\n",
      "Closed: \u001b[1m168440\u001b[0m times (\u001b[1m17.14%)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "total_days = len(train_df)\n",
    "\n",
    "closed_count = (train_df['open'] == 0).sum()\n",
    "opened_count = (train_df['open'] == 1).sum()\n",
    "\n",
    "print(f\"Opened: {bold_start}{opened_count}{bold_end} times ({bold_start}{(opened_count / total_days) * 100:.2f}%){bold_end}\")\n",
    "print(f\"Closed: {bold_start}{closed_count}{bold_end} times ({bold_start}{(closed_count / total_days) * 100:.2f}%){bold_end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b06d93-59b8-4d2f-b1cc-d58b6504559b",
   "metadata": {},
   "source": [
    "#### 7. Check for zero Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bda88f2c-b95a-46d4-a0b8-b2a63dde1ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are \u001b[1m168494\u001b[0m times when stores made no sales.\n"
     ]
    }
   ],
   "source": [
    "no_sales_count = (train_df['sales'] == 0).sum()\n",
    "print(f\"\\nThere are {bold_start}{no_sales_count}{bold_end} times when stores made no sales.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69ab582-11ee-47d9-9708-f3606913944d",
   "metadata": {},
   "source": [
    "#### 8. Check for Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08aefe83-250a-4d11-914a-c774fa7a3c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are \u001b[1m814150\u001b[0m times when stores recorded sales.\n"
     ]
    }
   ],
   "source": [
    "sales_count = (train_df['sales'] != 0).sum()\n",
    "print(f\"\\nThere are {bold_start}{sales_count}{bold_end} times when stores recorded sales.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e20e9f8-1480-46ae-8bf1-1e628f53299c",
   "metadata": {},
   "source": [
    "#### 9. Compare Sales vs No Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa38cf99-e0ba-4c67-bb91-2d243f444750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales: \u001b[1m814150\u001b[0m  times (\u001b[1m82.85%)\u001b[0m\n",
      "No-sales: \u001b[1m168494\u001b[0m times (\u001b[1m17.15%)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "total_days = len(train_df)\n",
    "\n",
    "print(f\"Sales: {bold_start}{sales_count}{bold_end}  times ({bold_start}{(sales_count / total_days) * 100:.2f}%){bold_end}\")\n",
    "print(f\"No-sales: {bold_start}{no_sales_count}{bold_end} times ({bold_start}{(no_sales_count / total_days) * 100:.2f}%){bold_end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea56e7c4-5aff-4d3b-85f3-d89c679c5851",
   "metadata": {},
   "source": [
    "#### 10. Customers Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59bf505c-b629-443f-8abf-790cc360fd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are \u001b[1m168492\u001b[0m times when no customers visited the stores.\n",
      "No-Customers: \u001b[1m168492\u001b[0m on (\u001b[1m17.15%)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "total_customers = len(train_df)\n",
    "no_customers_count = (train_df['customers'] == 0).sum()\n",
    "\n",
    "print(f\"\\nThere are {bold_start}{no_customers_count}{bold_end} times when no customers visited the stores.\")\n",
    "print(f\"No-Customers: {bold_start}{no_customers_count}{bold_end} on ({bold_start}{(no_customers_count / total_customers) * 100:.2f}%){bold_end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a585af-96ca-49c6-b002-69508f5cd209",
   "metadata": {},
   "source": [
    "#### 11. Impact of Day of the Week - Average Customers and Sales by Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "801a3a78-23fe-4360-b717-d69f09cb236c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dayofweek  avg_customers  avg_sales\n",
      "0          1         812.93    7797.64\n",
      "1          2         761.86    7005.52\n",
      "2          3         721.20    6536.45\n",
      "3          4         695.78    6216.11\n",
      "4          5         742.53    6703.50\n",
      "5          6         658.76    5856.78\n",
      "6          7          35.58     202.62\n"
     ]
    }
   ],
   "source": [
    "day_analysis = (\n",
    "    train_df.groupby('dayofweek')[['customers', 'sales']]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'customers': 'avg_customers', 'sales': 'avg_sales'})\n",
    ")\n",
    "\n",
    "print(day_analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073acc1c-77aa-4835-b75b-feb8fd0f1059",
   "metadata": {},
   "source": [
    "#### 12. Impact of Promotion - Average Customers and Sales by Promotion Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23210b99-59a8-45eb-abe3-1953c8407fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   promo  avg_customers  avg_sales\n",
      "0      0         517.45    4397.13\n",
      "1      1         820.77    7984.12\n"
     ]
    }
   ],
   "source": [
    "promo_analysis = (\n",
    "    train_df.groupby('promo')[['customers', 'sales']]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'customers': 'avg_customers', 'sales': 'avg_sales'})\n",
    ")\n",
    "\n",
    "print(promo_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3c7c4e-b4b6-4151-819d-647b0e698398",
   "metadata": {},
   "source": [
    "#### 13. Day of Week Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30483fae-bb92-48b6-b76c-b6f2f4ba9283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dayofweek  avg_customers  avg_sales\n",
      "0          1         812.93    7797.64\n",
      "1          2         761.86    7005.52\n",
      "2          3         721.20    6536.45\n",
      "3          4         695.78    6216.11\n",
      "4          5         742.53    6703.50\n",
      "5          6         658.76    5856.78\n",
      "6          7          35.58     202.62\n"
     ]
    }
   ],
   "source": [
    "# Average customers and sales by day of the week\n",
    "dow_analysis = (\n",
    "    train_df\n",
    "    .groupby(\"dayofweek\")[[\"customers\", \"sales\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"customers\": \"avg_customers\", \"sales\": \"avg_sales\"})\n",
    ")\n",
    "\n",
    "print(dow_analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9208e3cb-c139-4b1e-bb91-b384c55f205d",
   "metadata": {},
   "source": [
    "#### 14. SchoolHoliday Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7252c6d2-3f9f-4a3a-b8ce-bd801d9e6646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   schoolholiday  avg_customers  avg_sales\n",
      "0              0         619.03    5627.01\n",
      "1              1         698.96    6405.44\n"
     ]
    }
   ],
   "source": [
    "schoolholiday_analysis = (\n",
    "    train_df\n",
    "    .groupby(\"schoolholiday\")[[\"customers\", \"sales\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"customers\": \"avg_customers\", \"sales\": \"avg_sales\"})\n",
    ")\n",
    "\n",
    "print(schoolholiday_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64a3a64-edd9-4539-83fb-20b4bad22878",
   "metadata": {},
   "source": [
    "#### 15. Top 10 Crowded Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a242ed97-9e37-4624-a73f-a27aff9b7762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   store  avg_customers\n",
      "0    733        3403.45\n",
      "1    262        3400.41\n",
      "2    562        3106.59\n",
      "3    769        3071.50\n",
      "4   1114        2652.57\n",
      "5    817        2605.20\n",
      "6   1097        2412.39\n",
      "7    335        2390.88\n",
      "8    259        2333.87\n",
      "9    251        2028.02\n"
     ]
    }
   ],
   "source": [
    "top10_crowded_store = (\n",
    "    train_df.groupby('store')['customers']\n",
    "    .mean()\n",
    "    .nlargest(10)\n",
    "    .reset_index()\n",
    "    .rename(columns={'customers': 'avg_customers'})\n",
    ")\n",
    "\n",
    "print(top10_crowded_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cef3916-7e62-48af-a825-15fd21d8d0db",
   "metadata": {},
   "source": [
    "#### 16. Top 10 Highest-Selling Stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6287c00-0354-473a-81f1-003adf46f38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   store  avg_sales\n",
      "0    262   20684.09\n",
      "1    817   18105.70\n",
      "2    562   17984.64\n",
      "3   1114   17097.69\n",
      "4    251   15814.01\n",
      "5    513   15133.66\n",
      "6    842   15117.74\n",
      "7    733   14945.51\n",
      "8    788   14930.54\n",
      "9    383   14294.00\n"
     ]
    }
   ],
   "source": [
    "top10_selling_store = (\n",
    "    train_df.groupby('store')['sales']\n",
    "    .mean()\n",
    "    .nlargest(10)\n",
    "    .reset_index()\n",
    "    .rename(columns={'sales': 'avg_sales'})\n",
    ")\n",
    "\n",
    "print(top10_selling_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795e5796-2080-4de1-b34a-48794d8351ec",
   "metadata": {},
   "source": [
    "#### 18. Crowded vs. Selling Stores - Sort by avg_sales in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79a453ff-6d2b-4a58-925b-c3217e5ca56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    store  avg_customers  avg_sales\n",
      "0     262        3400.41   20684.09\n",
      "1     817        2605.20   18105.70\n",
      "2     562        3106.59   17984.64\n",
      "3    1114        2652.57   17097.69\n",
      "4     251        2028.02   15814.01\n",
      "5     513           0.00   15133.66\n",
      "6     842           0.00   15117.74\n",
      "7     733        3403.45   14945.51\n",
      "8     788           0.00   14930.54\n",
      "9     383           0.00   14294.00\n",
      "10    335        2390.88       0.00\n",
      "11    259        2333.87       0.00\n",
      "12    769        3071.50       0.00\n",
      "13   1097        2412.39       0.00\n"
     ]
    }
   ],
   "source": [
    "comparison_df = (\n",
    "    pd.merge(top10_crowded_store, top10_selling_store, on='store', how='outer')\n",
    "    .fillna(0)\n",
    "    .sort_values(by='avg_sales', ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228bffc3-2e6c-44db-9c54-5202a5103f95",
   "metadata": {},
   "source": [
    "#### 19. Dual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "000c987b-4bf4-4743-90a2-c7ac549ff922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    store  avg_customers  avg_sales  top_both\n",
      "0     262        3400.41   20684.09      True\n",
      "1     817        2605.20   18105.70      True\n",
      "2     562        3106.59   17984.64      True\n",
      "3    1114        2652.57   17097.69      True\n",
      "4     251        2028.02   15814.01      True\n",
      "5     513           0.00   15133.66     False\n",
      "6     842           0.00   15117.74     False\n",
      "7     733        3403.45   14945.51      True\n",
      "8     788           0.00   14930.54     False\n",
      "9     383           0.00   14294.00     False\n",
      "10    335        2390.88       0.00     False\n",
      "11    259        2333.87       0.00     False\n",
      "12    769        3071.50       0.00     False\n",
      "13   1097        2412.39       0.00     False\n"
     ]
    }
   ],
   "source": [
    "comparison_df['top_both'] = (\n",
    "    comparison_df['store'].isin(top10_crowded_store['store']) &\n",
    "    comparison_df['store'].isin(top10_selling_store['store'])\n",
    ")\n",
    "\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945f1093-299f-4edd-80e7-6c34976481df",
   "metadata": {},
   "source": [
    "## 4. Features Engineering - Use for Visualization only \n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11c6b500-81ee-4974-bd37-3894c0d10cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Days type distribution:\n",
      "day  isweekend\n",
      "Tue  False        141204\n",
      "Mon  False        140270\n",
      "Fri  False        140270\n",
      "Sat  True         140270\n",
      "Sun  True         140270\n",
      "Thu  False        140270\n",
      "Wed  False        140090\n",
      "Name: count, dtype: int64\n",
      "\n",
      "[2013 2014 2015]\n",
      "int32\n"
     ]
    }
   ],
   "source": [
    "# Make a copy of the original dataframe to avoid modifying it\n",
    "df_viz_feat = train_df.copy()\n",
    "\n",
    "# Ensure date column is in datetime format\n",
    "if not pd.api.types.is_datetime64_any_dtype(df_viz_feat['date']):\n",
    "    df_viz_feat['date'] = pd.to_datetime(df_viz_feat['date'])\n",
    "\n",
    "# Sort by date in ascending order, in place\n",
    "df_viz_feat.sort_values(by='date', ascending=True, inplace=True)\n",
    "\n",
    "# Create Time-based Covariates - Basic Temporal Features\n",
    "df_viz_feat['day'] = df_viz_feat['date'].dt.strftime('%a')\n",
    "df_viz_feat['week'] = df_viz_feat['date'].dt.isocalendar().week\n",
    "df_viz_feat['month'] = df_viz_feat['date'].dt.strftime('%b')\n",
    "df_viz_feat['quarter'] = df_viz_feat['date'].dt.quarter\n",
    "df_viz_feat['year'] = df_viz_feat['date'].dt.year\n",
    "df_viz_feat['isweekend']= df_viz_feat['dayofweek'] > 5\n",
    "\n",
    "print(f\"\\nDays type distribution:\\n{df_viz_feat[['day', 'isweekend']].value_counts()}\\n\")\n",
    "\n",
    "print(df_viz_feat['year'].unique())\n",
    "print(df_viz_feat['year'].dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6518445-c9a5-45ec-9d5d-1adc3b192204",
   "metadata": {},
   "source": [
    "#### 4.1. StateHoliday Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42ded3a6-d845-4778-87ba-50ae0e9a8752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmapped rows after mapping:\n",
      "Empty DataFrame\n",
      "Columns: [stateholiday]\n",
      "Index: []\n",
      "\n",
      "Holiday type distribution:\n",
      "stateholiday\n",
      "Normal Day    951594\n",
      "Public         20260\n",
      "Easter          6690\n",
      "Christmas       4100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Define the holiday type mapping\n",
    "holiday_map = {\n",
    "    \"0\": \"Normal Day\",\n",
    "    \"a\": \"Public\",\n",
    "    \"b\": \"Easter\",\n",
    "    \"c\": \"Christmas\"  \n",
    "}\n",
    "\n",
    "df_viz_feat['stateholiday']= df_viz_feat['stateholiday'].map(holiday_map)\n",
    "\n",
    "# Create IsHoliday feature\n",
    "df_viz_feat['isholiday']= df_viz_feat['stateholiday'] !=\"Normal Day\"\n",
    "\n",
    "# IsSchool Feature - Rule: assume school is out for Public, Easter, and Christmas Breaks\n",
    "df_viz_feat[\"isschoolDay\"] = ~df_viz_feat[\"stateholiday\"].isin([\"Public\", \"Easter\", \"Christmas\"])\n",
    "\n",
    "# Mapping Check\n",
    "unmapped_rows = df_viz_feat[df_viz_feat['stateholiday'].isna()]\n",
    "print(f\"Unmapped rows after mapping:\\n{unmapped_rows[['stateholiday']]}\")\n",
    "\n",
    "# Print the count of each holiday type, including any missing (NaN) values for unmapped entries\n",
    "print(f\"\\nHoliday type distribution:\\n{df_viz_feat['stateholiday'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3ad2b7-6958-4671-992f-96a6d9945525",
   "metadata": {},
   "source": [
    "#### Promo mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a92caf26-bda2-4f35-b865-f080e0d89adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_viz_feat['promo'] = df_viz_feat['promo'].astype(str).map({'1': 'Promo', '0': 'No Promo'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef7908b-5c4e-424b-bc2c-a65ad115397b",
   "metadata": {},
   "source": [
    "#### Features Enginerring check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33a6076b-84c9-456c-974e-fcf99b5e686c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape after before features Engineering: (982644, 9)\n",
      "The shape after adding features : (982644, 17)\n"
     ]
    }
   ],
   "source": [
    "print(f'The shape after before features Engineering: {train_df.shape}')\n",
    "print(f'The shape after adding features : {df_viz_feat.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "788319eb-00ff-4093-9e10-60df00f344e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "      <th>customers</th>\n",
       "      <th>open</th>\n",
       "      <th>promo</th>\n",
       "      <th>stateholiday</th>\n",
       "      <th>schoolholiday</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>month</th>\n",
       "      <th>quarter</th>\n",
       "      <th>year</th>\n",
       "      <th>isweekend</th>\n",
       "      <th>isholiday</th>\n",
       "      <th>isschoolDay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>982643</th>\n",
       "      <td>1115</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Promo</td>\n",
       "      <td>Public</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982640</th>\n",
       "      <td>1112</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Promo</td>\n",
       "      <td>Public</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982639</th>\n",
       "      <td>1111</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Promo</td>\n",
       "      <td>Public</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982638</th>\n",
       "      <td>1110</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Promo</td>\n",
       "      <td>Public</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982637</th>\n",
       "      <td>1109</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No Promo</td>\n",
       "      <td>Public</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        store  dayofweek       date  sales  customers  open     promo stateholiday  schoolholiday  day  week month  quarter  year  isweekend  isholiday  isschoolDay\n",
       "982643   1115          2 2013-01-01      0          0     0  No Promo       Public              1  Tue     1   Jan        1  2013      False       True        False\n",
       "982640   1112          2 2013-01-01      0          0     0  No Promo       Public              1  Tue     1   Jan        1  2013      False       True        False\n",
       "982639   1111          2 2013-01-01      0          0     0  No Promo       Public              1  Tue     1   Jan        1  2013      False       True        False\n",
       "982638   1110          2 2013-01-01      0          0     0  No Promo       Public              1  Tue     1   Jan        1  2013      False       True        False\n",
       "982637   1109          2 2013-01-01      0          0     0  No Promo       Public              1  Tue     1   Jan        1  2013      False       True        False"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_viz_feat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "571b6b1d-ba96-4299-a935-6d4a8bcfcfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'train_df' (DataFrame)\n",
      "Stored 'df_viz_feat' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "# To pull train_df from one notebook to another in JupyterLab\n",
    "%store train_df\n",
    "%store df_viz_feat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b33402-11dd-471a-b9c2-effe7f65283b",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4734fdac-47a4-4b96-9633-c77a9fd333be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data Ingestion and Exploratory Data Analysis completed successfully!\n",
      "üóìÔ∏è Analysis Date: \u001b[1m2025-08-13 21:10:12\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"‚úÖ Data Ingestion and Exploratory Data Analysis completed successfully!\")\n",
    "print(f\"üóìÔ∏è Analysis Date: {bold_start}{pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}{bold_end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fb3d94-675d-4cea-bc83-2e995e1e8c94",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2a578a31-6bf1-4605-8d14-c69c3df0809c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Analysis Summary\n",
      "üü¢ Begin Date: \u001b[1m2025-08-13 21:09:59\u001b[0m\n",
      "‚úÖ End Date:   \u001b[1m2025-08-13 21:10:12\u001b[0m\n",
      "‚è±Ô∏è Duration:   \u001b[1m0 days 00:00:12.963469\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# End analysis\n",
    "analysis_end = pd.Timestamp.now()\n",
    "duration = analysis_end - analysis_begin\n",
    "\n",
    "# Final summary print\n",
    "print(\"\\nüìã Analysis Summary\")\n",
    "print(f\"üü¢ Begin Date: {bold_start}{analysis_begin.strftime('%Y-%m-%d %H:%M:%S')}{bold_end}\")\n",
    "print(f\"‚úÖ End Date:   {bold_start}{analysis_end.strftime('%Y-%m-%d %H:%M:%S')}{bold_end}\")\n",
    "print(f\"‚è±Ô∏è Duration:   {bold_start}{str(duration)}{bold_end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045b4131-f856-44b5-81e8-1f72274952fa",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "## Project Design Rationale: Notebook Separation\n",
    "\n",
    "To promote **clarity, maintainability, and scalability** within the project, **data engineering** and **visualization tasks** are intentionally separated into distinct notebooks. This modular approach prevents the accumulation of excessive code in a single notebook, making it easier to **debug, update, and collaborate across different stages of the workflow**. By isolating data transformation logic from visual analysis, **each notebook remains focused and purpose-driven**, ultimately **enhancing the overall efficiency and readability of the project**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
