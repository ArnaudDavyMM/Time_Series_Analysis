{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56ef5700-bd71-4e44-99c4-6f17485d94f5",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "\n",
    "This project is structured into **four major components**, each addressing a critical phase of **time series forecasting** using the **Rossmann Store Sales dataset**:\n",
    "\n",
    "üîπ **Part 1**: Data Ingestion, Exploratory Data Analysis (EDA)\n",
    "\n",
    "We begin by importing the dataset, performing a thorough exploratory data analysis to assess data quality, uncover patterns, and identify potential issues such as missing values, anomalies, and inconsistencies.\n",
    "\n",
    "üîπ **Part 2**: Feature Engineering and Data Visualization\n",
    "\n",
    "This section delves into engineering relevant features (predictors) to prepare the data for modeling and presents key visualizations to uncover underlying trends, recurring patterns, and seasonal effects.\n",
    "\n",
    "üîπ **Part 3**: Classical Time Series Analysis and Forecasting\n",
    "\n",
    "This section focuses on widely adopted forecasting techniques in the data science domain. We will implement and evaluate several standard algorithms, including:\n",
    "\n",
    " - **Statistical Models**: ARIMA, SARIMA\n",
    "    \n",
    " - **Ensemble Methods:** XGBoost, LightGBM\n",
    "    \n",
    " - **Facebook Prophet:** A robust model for time series forecasting with built-in seasonality and holiday effects\n",
    "    \n",
    " - **Deep Learning Models:** LSTM, Temporal Fusion Transformers (TFT), N-BEATS\n",
    "\n",
    "üîπ **Part 4**: Hybrid Time Series Forecasting\n",
    "\n",
    "This advanced section explores hybrid modeling approaches typically used by experienced data scientists. These models combine the strengths of multiple algorithms to improve forecasting accuracy:\n",
    "\n",
    " - **ARIMA + XGBoost**\n",
    "    \n",
    " - **Prophet + LightGBM / XGBoost**\n",
    "    \n",
    " - **Prophet + LSTM**\n",
    "    \n",
    " - **TFT + ARIMA**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12025e3-180d-4431-99fd-8bccc2a93bab",
   "metadata": {},
   "source": [
    " # Model Selection Strategy\n",
    "----------------------------\n",
    "\n",
    "The choice of forecasting algorithm depends on the characteristics of the dataset and the domain expertise of the practitioner. In this project, we will experiment with all the above methods and compare their performance to determine the most effective approach for our data.\n",
    "\n",
    "**Let‚Äôs dive in and explore which model delivers the most accurate forecasts!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226b3337-c185-4bb0-adad-9ec9f641d3e6",
   "metadata": {},
   "source": [
    "## Part 1: Data Ingestion and Exploratory Data Analysis (EDA)\n",
    "-------------------------------------------------------------\n",
    "\n",
    "In this section, we will focus on **ingesting** the Rossmann Store Sales dataset and conducting a comprehensive **Exploratory Data Analysis (EDA)** prior to applying time series modeling and forecasting techniques. The workflow will proceed through the following steps:\n",
    "\n",
    "1. **Import Libraries and Dependencies:** Load all necessary Python libraries and packages required for data manipulation, visualization, and analysis.\n",
    "\n",
    "1. **Data Ingestion:** Load the Rossmann Store Sales dataset into the working environment for analysis.\n",
    "\n",
    "3. **Exploratory Data Analysis (EDA):** Perform a detailed examination of the dataset to understand its structure and key characteristics:\n",
    "\n",
    "   - **Inspect dataset metadata**: data types, number of observations (rows), and variables (columns)\n",
    "\n",
    "    - **Identify and quantify missing values**\n",
    "\n",
    "    - **Detect and handle duplicate records**\n",
    "\n",
    "    - **Generate summary statistics** (mean, median, standard deviation, etc.)\n",
    "\n",
    "    - **Analyze individual features and their distributions**\n",
    "\n",
    "    - **Apply feature engineering techniques to enhance model readiness**\n",
    "\n",
    "    - **Evaluate feature correlations to identify relationships**\n",
    "\n",
    "    - **Visualize data using appropriate plots and charts**\n",
    "\n",
    "    - **Conduct deeper analysis to uncover trends, patterns, and seasonality within the time series**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd832622-b6c7-4b7f-a4ef-26eeea11e6a1",
   "metadata": {},
   "source": [
    "## 1. Setup & Imports Libraries\n",
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21a4ece7-9e78-4878-b52b-28605ad85ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4563f70e-b121-4e17-8522-e90be7726f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Setup and Import Libraries in progress...\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Data Ingestion\n",
    "print(\"Step 1: Setup and Import Libraries in progress...\")\n",
    "time.sleep(1)  # Simulate processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75d6c5fa-aee0-4e1f-9e59-840fdba88e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Rossman Store Sales Time Series Analysis - Part 1\n",
      "============================================================\n",
      "All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Data Manipulation & Processing\n",
    "import os\n",
    "import holidays\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import scipy.stats as stats\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import *\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format','{:.2f}'.format)\n",
    "\n",
    "# Warnings\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Rossman Store Sales Time Series Analysis - Part 1\")\n",
    "print(\"=\"*60)\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28356173-747b-4d1f-8398-e5ccca45e36a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup and Import Liraries completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"‚úÖ Setup and Import Liraries completed.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cce5b68-7d10-4d23-aa9f-34b449a511ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Analysis Started\n",
      "üü¢ Begin Date: \u001b[1m2025-08-07 00:37:22\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Start analysis\n",
    "\n",
    "analysis_begin = pd.Timestamp.now()\n",
    "\n",
    "bold_start = '\\033[1m'\n",
    "bold_end = '\\033[0m'\n",
    "\n",
    "print(\"üîç Analysis Started\")\n",
    "print(f\"üü¢ Begin Date: {bold_start}{analysis_begin.strftime('%Y-%m-%d %H:%M:%S')}{bold_end}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ca539c-3bf4-4d74-bc5a-0b4a77793146",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Data Ingestion\n",
    "----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "705d6ee5-e88f-43e5-89fd-6e454bfb56d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Data Ingestion in progress...\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Data Ingestion\n",
    "print(\"Step 2: Data Ingestion in progress...\")\n",
    "time.sleep(1)  # Simulate processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e24c581c-c5aa-4b97-ab72-64a64f2e9f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for files in: /home/mukwa/Desktop/Time_Series_Analysis/data\n",
      "\n",
      "Train file exists: True\n",
      "Test file exists: True\n",
      "\n",
      "Files loaded successfully!\n",
      "\n",
      "Train data shape: (982644, 9)\n",
      "Test data shape: (34565, 9)\n",
      "\n",
      "There are : 982644 Rows and 9 Columns in training data\n",
      "There are : 34565 Rows and 9 Columns in testing data\n"
     ]
    }
   ],
   "source": [
    "# Use absolute path to avoid pwd issues\n",
    "base_path = Path.home() / \"Desktop\" / \"Time_Series_Analysis\"/\"data\"\n",
    "train_path = base_path / \"Retail_train_data.csv\"\n",
    "test_path = base_path / \"Retail_test_data.csv\"\n",
    "\n",
    "# Check if files exist\n",
    "print(f\"Looking for files in: {base_path}\\n\")\n",
    "print(f\"Train file exists: {train_path.exists()}\")\n",
    "print(f\"Test file exists: {test_path.exists()}\")\n",
    "\n",
    "if train_path.exists() and test_path.exists():\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    print(\"\\nFiles loaded successfully!\\n\")\n",
    "    print(f\"Train data shape: {train_df.shape}\")\n",
    "    print(f\"Test data shape: {test_df.shape}\\n\")\n",
    "    print('There are : %s Rows and %s Columns in training data' % (str(train_df.shape[0]) ,str(train_df.shape[1])))\n",
    "    print('There are : %s Rows and %s Columns in testing data' % (str(test_df.shape[0]) ,str(test_df.shape[1])))\n",
    "else:\n",
    "    print(\"Files not found. Please check the file paths and names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1fe1b626-5584-493e-89b2-4b13da6daec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data Ingestion completed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"‚úÖ Data Ingestion completed.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5988d899-2b50-45c1-82de-8e6e2c196546",
   "metadata": {},
   "source": [
    "# 3. Exploratory Data Analysis (EDA)\n",
    "## 3.1. Basic Inspection\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48fb8f22-7014-4523-8a1b-7a6338f396a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Step 3: Exploratory Data Analysis in progress...\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Exploratory Data Analysis (EDA)\n",
    "print(\"üìä Step 3: Exploratory Data Analysis in progress...\")\n",
    "time.sleep(1)  # Simulate processing time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4157b20d-8631-44d4-9512-0f305dbd184e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 982644 entries, 0 to 982643\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count   Dtype \n",
      "---  ------         --------------   ----- \n",
      " 0   store          982644 non-null  int64 \n",
      " 1   dayofweek      982644 non-null  int64 \n",
      " 2   date           982644 non-null  object\n",
      " 3   sales          982644 non-null  int64 \n",
      " 4   customers      982644 non-null  int64 \n",
      " 5   open           982644 non-null  int64 \n",
      " 6   promo          982644 non-null  int64 \n",
      " 7   stateholiday   982644 non-null  object\n",
      " 8   schoolholiday  982644 non-null  int64 \n",
      "dtypes: int64(7), object(2)\n",
      "memory usage: 67.5+ MB\n"
     ]
    }
   ],
   "source": [
    "train_df.columns = train_df.columns.str.lower()\n",
    "test_df.columns = test_df.columns.str.lower()\n",
    "\n",
    "# --- BASIC INFO AND DUPLICATES ---\n",
    "print(\"DataFrame Info:\")\n",
    "train_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b18d13a-bcf7-4377-b468-a9ff17d584e8",
   "metadata": {},
   "source": [
    "## View or Display Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c2f2327-6fa3-4c87-8cb8-57cca0d61d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Data Preview:\n",
      "   store  dayofweek        date  sales  customers  open  promo stateholiday  schoolholiday\n",
      "0      1          2  2015-06-30   5735        568     1      1            0              0\n",
      "1      2          2  2015-06-30   9863        877     1      1            0              0\n",
      "2      3          2  2015-06-30  13261       1072     1      1            0              1\n",
      "3      4          2  2015-06-30  13106       1488     1      1            0              0\n",
      "4      5          2  2015-06-30   6635        645     1      1            0              0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTrain Data Preview:\")\n",
    "print(train_df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef996b4e-34d3-421d-a3a5-7c04ff033f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('2013-01-01', '2015-06-30')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['date'].min(), train_df['date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ada5a0bc-0ca6-450f-b03c-79e1d74795c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Data Preview:\n",
      "        store  dayofweek        date  sales  customers  open  promo stateholiday  schoolholiday\n",
      "982643   1115          2  2013-01-01      0          0     0      0            a              1\n",
      "981908    379          2  2013-01-01      0          0     0      0            a              1\n",
      "981907    378          2  2013-01-01      0          0     0      0            a              1\n",
      "981906    377          2  2013-01-01      0          0     0      0            a              1\n",
      "981905    376          2  2013-01-01      0          0     0      0            a              1 \n",
      "\n",
      "\n",
      "Test Data Preview:\n",
      "       store  dayofweek        date  sales  customers  open  promo  stateholiday  schoolholiday\n",
      "34560   1111          3  2015-07-01   3701        351     1      1             0              1\n",
      "34561   1112          3  2015-07-01  10620        716     1      1             0              1\n",
      "34562   1113          3  2015-07-01   8222        770     1      1             0              0\n",
      "34563   1114          3  2015-07-01  27071       3788     1      1             0              0\n",
      "34564   1115          3  2015-07-01   7701        447     1      1             0              0\n"
     ]
    }
   ],
   "source": [
    "train_df.sort_values('date', inplace =True, ascending =True)\n",
    "\n",
    "print(\"\\nTrain Data Preview:\")\n",
    "print(train_df.head(), \"\\n\")\n",
    "print(\"\\nTest Data Preview:\")\n",
    "print(test_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "162ffbfb-ae1a-4ef3-ac43-57f4f1aa0897",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Data Preview:\n",
      "        store  dayofweek        date  sales  customers  open  promo stateholiday  schoolholiday\n",
      "982643   1115          2  2013-01-01      0          0     0      0            a              1\n",
      "981908    379          2  2013-01-01      0          0     0      0            a              1\n",
      "981907    378          2  2013-01-01      0          0     0      0            a              1\n",
      "981906    377          2  2013-01-01      0          0     0      0            a              1\n",
      "981905    376          2  2013-01-01      0          0     0      0            a              1 \n",
      "\n",
      "\n",
      "Test Data Preview:\n",
      "     store  dayofweek        date  sales  customers  open  promo  stateholiday  schoolholiday\n",
      "745    746          5  2015-07-31   9082        638     1      1             0              1\n",
      "746    747          5  2015-07-31  10708        826     1      1             0              1\n",
      "747    748          5  2015-07-31   7481        578     1      1             0              1\n",
      "741    742          5  2015-07-31  10460       1016     1      1             0              1\n",
      "0        1          5  2015-07-31   5263        555     1      1             0              1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_df.sort_values('date', inplace =True, ascending =True)\n",
    "\n",
    "print(\"\\nTest Data Preview:\")\n",
    "print(train_df.head(), \"\\n\")\n",
    "print(\"\\nTest Data Preview:\")\n",
    "print(test_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d02c3b83-bb1c-41e8-95af-6f51d470adf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values per Column:\n",
      "store            0\n",
      "dayofweek        0\n",
      "date             0\n",
      "sales            0\n",
      "customers        0\n",
      "open             0\n",
      "promo            0\n",
      "stateholiday     0\n",
      "schoolholiday    0\n",
      "dtype: int64\n",
      "\n",
      "Number of duplicated rows: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing Values per Column:\")\n",
    "print(train_df.isna().sum())\n",
    "print('\\nNumber of duplicated rows:', train_df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73df65c-335a-4a11-9fa5-c5fb83df4be4",
   "metadata": {},
   "source": [
    "## 3.2 Summary Statistics\n",
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a6e0c87-14b2-4890-a2db-9a6d5b28ae97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary Statistics:\n",
      "          store  dayofweek     sales  customers      open     promo  schoolholiday\n",
      "count 982644.00  982644.00 982644.00  982644.00 982644.00 982644.00      982644.00\n",
      "mean     558.44       4.00   5760.84     632.77      0.83      0.38           0.17\n",
      "std      321.91       2.00   3857.57     465.40      0.38      0.49           0.38\n",
      "min        1.00       1.00      0.00       0.00      0.00      0.00           0.00\n",
      "25%      280.00       2.00   3705.00     403.00      1.00      0.00           0.00\n",
      "50%      558.00       4.00   5731.00     609.00      1.00      0.00           0.00\n",
      "75%      838.00       6.00   7847.00     838.00      1.00      1.00           0.00\n",
      "max     1115.00       7.00  41551.00    7388.00      1.00      1.00           1.00\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSummary Statistics:\")\n",
    "print(train_df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c0067e-5ac7-479f-8604-868b77d5da11",
   "metadata": {},
   "source": [
    "----------------------------------------------------\n",
    "\n",
    "### This my previous version of Statistical Analysis\n",
    "\n",
    "1. **Store-Level Insights :**\n",
    " *  Store IDs range from **1 to 1115**, suggesting over a thousand **(1115)** unique stores in the dataset.\n",
    " *  The distribution of store IDs **(mean ‚âà 558, std ‚âà 322)** implies a relatively even spread across stores, but some clustering may exist around the median (558).\n",
    "   \n",
    "2. **Temporal Patterns :**\n",
    " *  DayOfWeek ranges from **1 to 7**, with a mean of **~4.00**‚Äîindicating a fairly uniform distribution of entries across all days.\n",
    " *  Could be interesting to examine how sales and customers vary by weekday, especially near the weekend peak **(e.g., Friday/Saturday)**.\n",
    "\n",
    "3. **Sales & Customer Traffic:**\n",
    " *  Average daily sales per entry: **5760.84** with a very wide spread **(std ‚âà 3857.57)**, and a maximum sale day of **$41,551**‚Äîa strong hint at major spikes for certain stores or events.\n",
    " *  Customer count averages **~633** per day, also with high variability **(max nearly 7,400)**, pointing to inconsistent foot traffic across locations and days.\n",
    " *  Zero-sales and zero-customer days are quite high **(‚âà 17% of records)**. These likely correspond to closed stores or unusual business days and should be accounted for in any forecasting or revenue analysis.\n",
    " *   The mean for sales is **5760.843 and the median 5731.00**, suggesting the **sales distribution is right skewed**\n",
    "\n",
    "5. **Store Availability:**\n",
    " *  Open flag mean is **0.829**, meaning stores are open roughly **83%** of the time.\n",
    "\n",
    "6. **Promotional Impact**\n",
    " *  38% of entries have active promotions, and sales/customer variability suggests these promotions could have significant but uneven impact.\n",
    " *  Worth analyzing sales uplift due to **Promo = 1 compared to Promo = 0**.\n",
    "\n",
    "7. **School Holidays**\n",
    " *  **Only 17.2%** of entries fall on a school holiday, suggesting that sales are not high on School Holidays\n",
    " *  This feature may influence customer counts, especially for stores near schools or those that rely on family shoppers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac88e20-31cf-42e1-8ade-5f0b8ffc841b",
   "metadata": {},
   "source": [
    "--------------------------------------------------------\n",
    "### This my current (updated) version of Statistical Analysis\n",
    "\n",
    "Looking at these retail summary statistics, several key insights emerge about this dataset's business patterns and data quality:\n",
    "\n",
    "**Business Operations Pattern**\n",
    "The data reveals a clear weekly rhythm with stores typically open **5-6 days per week (82.9% open rate)**. The day-of-week distribution **(mean ~4.0, std 2.0)** suggests relatively even coverage across the week, though weekends likely see different patterns given the standard deviation.\n",
    "\n",
    "**Sales Performance Distribution**\n",
    "Daily sales **average ‚Ç¨5,761** with substantial variation **(std ‚Ç¨3,858)**, indicating significant differences between high and low-performing periods. The distribution appears right-skewed, as the **median (‚Ç¨5,731)** sits below the **75th percentile (‚Ç¨7,847)**, while the **maximum of ‚Ç¨41,551** represents exceptional peak performance days.\n",
    "\n",
    "**Customer traffic** follows a similar pattern, **averaging 633 customers per day** with the same **right-skewed distribution**. The sales-to-customer ratio of approximately **‚Ç¨9.11 per customer** suggests this could be a grocery or everyday retail environment.\n",
    "\n",
    "**Promotional and Seasonal Effects**\n",
    "Promotions run on **38%** of operating days, suggesting strategic rather than constant promotional activity. School holidays affect only **17.2%** of the dataset, indicating this captures mostly regular school periods with some holiday shopping included.\n",
    "\n",
    "**Data Quality Concerns**\n",
    "The most striking finding is that **168,494 rows (17.1%)** show zero sales, with an almost identical number showing zero customers **(168,492)**. This near-perfect correlation suggests these represent genuine store closures rather than data collection errors. These closed days significantly impact the overall averages and explain why the \"Open\" variable shows **82.9% rather than 100%**.\n",
    "\n",
    "**Strategic Implications**\n",
    "The wide performance range and promotional frequency suggest opportunities for optimizing both timing and targeting of marketing efforts. The substantial day-to-day variation in both sales and customer counts indicates strong external factors **(likely day-of-week effects, promotions, and seasonal patterns)** that could be leveraged for better forecasting and inventory management.\n",
    "\n",
    "This appears to be a comprehensive retail dataset suitable for time series analysis, promotional effectiveness studies, and customer behavior modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45247aa9-f293-427d-adae-d03d3818cb50",
   "metadata": {},
   "source": [
    "## 3.3 Variables Analysis\n",
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994dda02-d381-4b67-9ff9-218d51511fad",
   "metadata": {},
   "source": [
    "#### 1. Suspicious Days (Quality Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa8f6250-3fe6-4d7f-b64f-30cb60f26e59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suspicious days with sales but no customers: 0\n"
     ]
    }
   ],
   "source": [
    "# Days with zero customers and non-zero sales (quality check)\n",
    "odd_days = train_df[(train_df[\"customers\"] == 0) & (train_df[\"sales\"] > 0)]\n",
    "print(f\"Suspicious days with sales but no customers: {odd_days.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83017689-aad1-4109-80bc-3a3fa25618f2",
   "metadata": {},
   "source": [
    "#### 2. Unique days of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d6a0d2f1-b11f-453f-9062-b4a6c6e5669d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique days of the week in the dataset: [1 2 3 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "unique_days = train_df['dayofweek'].sort_values().unique()\n",
    "print(f\"Unique days of the week in the dataset: {unique_days}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e025485-2e4b-46c3-b930-6336926a488a",
   "metadata": {},
   "source": [
    "#### 3. Unique State Holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5704f52-6f19-4baa-82f6-c44eca943653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique State holiday in the dataset: ['a' '0' 'b' 'c' 0]\n"
     ]
    }
   ],
   "source": [
    "unique_stateholiday = train_df['stateholiday'].unique()\n",
    "print(f\"Unique State holiday in the dataset: {unique_stateholiday}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f21f10af-38df-421d-80bd-dca2738927e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Holiday Value Counts:\n",
      "stateholiday\n",
      "0    951594\n",
      "a     20260\n",
      "b      6690\n",
      "c      4100\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# -- That mix of '0' (string) and 0 (integer) in your array means the column has inconsistent data types ‚Äî which can definitely mess up mappings and analysis.\n",
    "\n",
    "# -- Clean the Data Types\n",
    "train_df['stateholiday'] = train_df['stateholiday'].astype(str)\n",
    "\n",
    "# --- Sorted Output with counts\n",
    "print(\"State Holiday Value Counts:\")\n",
    "print(train_df['stateholiday'].value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870e7454-0f13-4ab8-8ced-8a3184e5fe39",
   "metadata": {},
   "source": [
    "-------------------------------------------------------\n",
    "### State Holidays namming convention\n",
    "\n",
    " .  **a** stands for **Public Holiday**\n",
    "\n",
    " .  **b** stands for **Easter Holiday**\n",
    "\n",
    " .  **c** stands for **Christmas Holiday**\n",
    "\n",
    " .  **0** or None means **No holiday**\n",
    "\n",
    "These codes were defined by the dataset creators to simplify **holiday categorization across German states**. So when we preprocess the data, we map those codes to their actual meanings to make analysis and visualization more intuitive.\n",
    "\n",
    "-------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca6a27a-0c32-4ca8-a851-49e24028f13c",
   "metadata": {},
   "source": [
    "#### 4. Closed Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4c9da22-8b7a-492d-bf70-7b5294d3782c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of times stores were closed: \u001b[1m168440\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "closed_count = (train_df['open'] == 0).sum()\n",
    "print(f\"\\nTotal number of times stores were closed: {bold_start}{closed_count}{bold_end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ef3703-7131-4d6c-899d-28b6014b1afd",
   "metadata": {},
   "source": [
    "#### 5. Opened_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01bafac5-9162-48f6-b8dd-6adca19e3b93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of times stores were opened: \u001b[1m814204\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "opened_count = (train_df['open'] == 1).sum()\n",
    "print(f\"\\nTotal number of times stores were opened: {bold_start}{opened_count}{bold_end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f2c7b7-90d6-4356-bbbd-acb1edb345b1",
   "metadata": {},
   "source": [
    "#### 6. Compare Open vs Closed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ea6be60-c7c9-40c7-bdb1-c7b9559d50f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opened: \u001b[1m814204\u001b[0m times (\u001b[1m82.86%)\u001b[0m\n",
      "Closed: \u001b[1m168440\u001b[0m times (\u001b[1m17.14%)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "total_days = len(train_df)\n",
    "\n",
    "closed_count = (train_df['open'] == 0).sum()\n",
    "opened_count = (train_df['open'] == 1).sum()\n",
    "\n",
    "print(f\"Opened: {bold_start}{opened_count}{bold_end} times ({bold_start}{(opened_count / total_days) * 100:.2f}%){bold_end}\")\n",
    "print(f\"Closed: {bold_start}{closed_count}{bold_end} times ({bold_start}{(closed_count / total_days) * 100:.2f}%){bold_end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b06d93-59b8-4d2f-b1cc-d58b6504559b",
   "metadata": {},
   "source": [
    "#### 7. Check for zero Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bda88f2c-b95a-46d4-a0b8-b2a63dde1ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are \u001b[1m168494\u001b[0m times when stores made no sales.\n"
     ]
    }
   ],
   "source": [
    "no_sales_count = (train_df['sales'] == 0).sum()\n",
    "print(f\"\\nThere are {bold_start}{no_sales_count}{bold_end} times when stores made no sales.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69ab582-11ee-47d9-9708-f3606913944d",
   "metadata": {},
   "source": [
    "#### 8. Check for Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "08aefe83-250a-4d11-914a-c774fa7a3c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are \u001b[1m814150\u001b[0m times when stores recorded sales.\n"
     ]
    }
   ],
   "source": [
    "sales_count = (train_df['sales'] != 0).sum()\n",
    "print(f\"\\nThere are {bold_start}{sales_count}{bold_end} times when stores recorded sales.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e20e9f8-1480-46ae-8bf1-1e628f53299c",
   "metadata": {},
   "source": [
    "#### 9. Compare Sales vs No Sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fa38cf99-e0ba-4c67-bb91-2d243f444750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales: \u001b[1m814150\u001b[0m  times (\u001b[1m82.85%)\u001b[0m\n",
      "No-sales: \u001b[1m168494\u001b[0m times (\u001b[1m17.15%)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "total_days = len(train_df)\n",
    "\n",
    "print(f\"Sales: {bold_start}{sales_count}{bold_end}  times ({bold_start}{(sales_count / total_days) * 100:.2f}%){bold_end}\")\n",
    "print(f\"No-sales: {bold_start}{no_sales_count}{bold_end} times ({bold_start}{(no_sales_count / total_days) * 100:.2f}%){bold_end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea56e7c4-5aff-4d3b-85f3-d89c679c5851",
   "metadata": {},
   "source": [
    "#### 10. Customers Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59bf505c-b629-443f-8abf-790cc360fd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are \u001b[1m168492\u001b[0m times when no customers visited the stores.\n",
      "No-Customers: \u001b[1m168492\u001b[0m on (\u001b[1m17.15%)\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "total_customers = len(train_df)\n",
    "no_customers_count = (train_df['customers'] == 0).sum()\n",
    "\n",
    "print(f\"\\nThere are {bold_start}{no_customers_count}{bold_end} times when no customers visited the stores.\")\n",
    "print(f\"No-Customers: {bold_start}{no_customers_count}{bold_end} on ({bold_start}{(no_customers_count / total_customers) * 100:.2f}%){bold_end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a585af-96ca-49c6-b002-69508f5cd209",
   "metadata": {},
   "source": [
    "#### 11. Impact of Day of the Week - Average Customers and Sales by Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "801a3a78-23fe-4360-b717-d69f09cb236c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dayofweek  avg_customers  avg_sales\n",
      "0          1         812.93    7797.64\n",
      "1          2         761.86    7005.52\n",
      "2          3         721.20    6536.45\n",
      "3          4         695.78    6216.11\n",
      "4          5         742.53    6703.50\n",
      "5          6         658.76    5856.78\n",
      "6          7          35.58     202.62\n"
     ]
    }
   ],
   "source": [
    "day_analysis = (\n",
    "    train_df.groupby('dayofweek')[['customers', 'sales']]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'customers': 'avg_customers', 'sales': 'avg_sales'})\n",
    ")\n",
    "\n",
    "print(day_analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073acc1c-77aa-4835-b75b-feb8fd0f1059",
   "metadata": {},
   "source": [
    "#### 12. Impact of Promotion - Average Customers and Sales by Promotion Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "23210b99-59a8-45eb-abe3-1953c8407fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   promo  avg_customers  avg_sales\n",
      "0      0         517.45    4397.13\n",
      "1      1         820.77    7984.12\n"
     ]
    }
   ],
   "source": [
    "promo_analysis = (\n",
    "    train_df.groupby('promo')[['customers', 'sales']]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={'customers': 'avg_customers', 'sales': 'avg_sales'})\n",
    ")\n",
    "\n",
    "print(promo_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3c7c4e-b4b6-4151-819d-647b0e698398",
   "metadata": {},
   "source": [
    "#### 13. Day of Week Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "30483fae-bb92-48b6-b76c-b6f2f4ba9283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   dayofweek  avg_customers  avg_sales\n",
      "0          1         812.93    7797.64\n",
      "1          2         761.86    7005.52\n",
      "2          3         721.20    6536.45\n",
      "3          4         695.78    6216.11\n",
      "4          5         742.53    6703.50\n",
      "5          6         658.76    5856.78\n",
      "6          7          35.58     202.62\n"
     ]
    }
   ],
   "source": [
    "# Average customers and sales by day of the week\n",
    "dow_analysis = (\n",
    "    train_df\n",
    "    .groupby(\"dayofweek\")[[\"customers\", \"sales\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"customers\": \"avg_customers\", \"sales\": \"avg_sales\"})\n",
    ")\n",
    "\n",
    "print(dow_analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9208e3cb-c139-4b1e-bb91-b384c55f205d",
   "metadata": {},
   "source": [
    "#### 14. SchoolHoliday Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7252c6d2-3f9f-4a3a-b8ce-bd801d9e6646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   schoolholiday  avg_customers  avg_sales\n",
      "0              0         619.03    5627.01\n",
      "1              1         698.96    6405.44\n"
     ]
    }
   ],
   "source": [
    "schoolholiday_analysis = (\n",
    "    train_df\n",
    "    .groupby(\"schoolholiday\")[[\"customers\", \"sales\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"customers\": \"avg_customers\", \"sales\": \"avg_sales\"})\n",
    ")\n",
    "\n",
    "print(schoolholiday_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64a3a64-edd9-4539-83fb-20b4bad22878",
   "metadata": {},
   "source": [
    "#### 15. Top 10 Crowded Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a242ed97-9e37-4624-a73f-a27aff9b7762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   store  avg_customers\n",
      "0    733        3403.45\n",
      "1    262        3400.41\n",
      "2    562        3106.59\n",
      "3    769        3071.50\n",
      "4   1114        2652.57\n",
      "5    817        2605.20\n",
      "6   1097        2412.39\n",
      "7    335        2390.88\n",
      "8    259        2333.87\n",
      "9    251        2028.02\n"
     ]
    }
   ],
   "source": [
    "top10_crowded_store = (\n",
    "    train_df.groupby('store')['customers']\n",
    "    .mean()\n",
    "    .nlargest(10)\n",
    "    .reset_index()\n",
    "    .rename(columns={'customers': 'avg_customers'})\n",
    ")\n",
    "\n",
    "print(top10_crowded_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cef3916-7e62-48af-a825-15fd21d8d0db",
   "metadata": {},
   "source": [
    "#### 16. Top 10 Highest-Selling Stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6287c00-0354-473a-81f1-003adf46f38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   store  avg_sales\n",
      "0    262   20684.09\n",
      "1    817   18105.70\n",
      "2    562   17984.64\n",
      "3   1114   17097.69\n",
      "4    251   15814.01\n",
      "5    513   15133.66\n",
      "6    842   15117.74\n",
      "7    733   14945.51\n",
      "8    788   14930.54\n",
      "9    383   14294.00\n"
     ]
    }
   ],
   "source": [
    "top10_selling_store = (\n",
    "    train_df.groupby('store')['sales']\n",
    "    .mean()\n",
    "    .nlargest(10)\n",
    "    .reset_index()\n",
    "    .rename(columns={'sales': 'avg_sales'})\n",
    ")\n",
    "\n",
    "print(top10_selling_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795e5796-2080-4de1-b34a-48794d8351ec",
   "metadata": {},
   "source": [
    "#### 18. Crowded vs. Selling Stores - Sort by avg_sales in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "79a453ff-6d2b-4a58-925b-c3217e5ca56a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    store  avg_customers  avg_sales\n",
      "0     262        3400.41   20684.09\n",
      "1     817        2605.20   18105.70\n",
      "2     562        3106.59   17984.64\n",
      "3    1114        2652.57   17097.69\n",
      "4     251        2028.02   15814.01\n",
      "5     513           0.00   15133.66\n",
      "6     842           0.00   15117.74\n",
      "7     733        3403.45   14945.51\n",
      "8     788           0.00   14930.54\n",
      "9     383           0.00   14294.00\n",
      "10    335        2390.88       0.00\n",
      "11    259        2333.87       0.00\n",
      "12    769        3071.50       0.00\n",
      "13   1097        2412.39       0.00\n"
     ]
    }
   ],
   "source": [
    "comparison_df = (\n",
    "    pd.merge(top10_crowded_store, top10_selling_store, on='store', how='outer')\n",
    "    .fillna(0)\n",
    "    .sort_values(by='avg_sales', ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228bffc3-2e6c-44db-9c54-5202a5103f95",
   "metadata": {},
   "source": [
    "#### 19. Dual Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "000c987b-4bf4-4743-90a2-c7ac549ff922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    store  avg_customers  avg_sales  top_both\n",
      "0     262        3400.41   20684.09      True\n",
      "1     817        2605.20   18105.70      True\n",
      "2     562        3106.59   17984.64      True\n",
      "3    1114        2652.57   17097.69      True\n",
      "4     251        2028.02   15814.01      True\n",
      "5     513           0.00   15133.66     False\n",
      "6     842           0.00   15117.74     False\n",
      "7     733        3403.45   14945.51      True\n",
      "8     788           0.00   14930.54     False\n",
      "9     383           0.00   14294.00     False\n",
      "10    335        2390.88       0.00     False\n",
      "11    259        2333.87       0.00     False\n",
      "12    769        3071.50       0.00     False\n",
      "13   1097        2412.39       0.00     False\n"
     ]
    }
   ],
   "source": [
    "comparison_df['top_both'] = (\n",
    "    comparison_df['store'].isin(top10_crowded_store['store']) &\n",
    "    comparison_df['store'].isin(top10_selling_store['store'])\n",
    ")\n",
    "\n",
    "print(comparison_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945f1093-299f-4edd-80e7-6c34976481df",
   "metadata": {},
   "source": [
    "## 4. Features Engineering\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11c6b500-81ee-4974-bd37-3894c0d10cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of the original dataframe to avoid modifying it\n",
    "df_features = train_df.copy()\n",
    "\n",
    "# Ensure date column is in datetime format\n",
    "if not pd.api.types.is_datetime64_any_dtype(df_features['date']):\n",
    "    df_features['date'] = pd.to_datetime(df_features['date'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e1a46e-d463-458a-8809-171598dc42c5",
   "metadata": {},
   "source": [
    "#### 4.1. Create Time-based Covariates -  Basic Temporal Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c13657d9-bb2e-428f-a2cc-654305f3b99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features['day'] = df_features['date'].dt.strftime('%a')\n",
    "df_features['week'] = df_features['date'].dt.isocalendar().week\n",
    "df_features['month'] = df_features['date'].dt.strftime('%b')\n",
    "df_features['quarter'] = df_features['date'].dt.quarter\n",
    "df_features['year'] = df_features['date'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6518445-c9a5-45ec-9d5d-1adc3b192204",
   "metadata": {},
   "source": [
    "#### 4.2. StateHoliday Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42ded3a6-d845-4778-87ba-50ae0e9a8752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the holiday type mapping\n",
    "holiday_map = {\n",
    "    \"0\": \"None\",\n",
    "    \"a\": \"Public\",\n",
    "    \"b\": \"Easter\",\n",
    "    \"c\": \"Christmas\"  \n",
    "}\n",
    "\n",
    "df_features['stateholiday']= df_features['stateholiday'].map(holiday_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef7908b-5c4e-424b-bc2c-a65ad115397b",
   "metadata": {},
   "source": [
    "#### Features Enginerring check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "33a6076b-84c9-456c-974e-fcf99b5e686c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape after feature Engineering : (982644, 14)\n"
     ]
    }
   ],
   "source": [
    "print(f'The shape after feature Engineering : {df_features.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "788319eb-00ff-4093-9e10-60df00f344e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store</th>\n",
       "      <th>dayofweek</th>\n",
       "      <th>date</th>\n",
       "      <th>sales</th>\n",
       "      <th>customers</th>\n",
       "      <th>open</th>\n",
       "      <th>promo</th>\n",
       "      <th>stateholiday</th>\n",
       "      <th>schoolholiday</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>month</th>\n",
       "      <th>quarter</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>982643</th>\n",
       "      <td>1115</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Public</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981908</th>\n",
       "      <td>379</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Public</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981907</th>\n",
       "      <td>378</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Public</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981906</th>\n",
       "      <td>377</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Public</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981905</th>\n",
       "      <td>376</td>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Public</td>\n",
       "      <td>1</td>\n",
       "      <td>Tue</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan</td>\n",
       "      <td>1</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        store  dayofweek       date  sales  customers  open  promo stateholiday  schoolholiday  day  week month  quarter  year\n",
       "982643   1115          2 2013-01-01      0          0     0      0       Public              1  Tue     1   Jan        1  2013\n",
       "981908    379          2 2013-01-01      0          0     0      0       Public              1  Tue     1   Jan        1  2013\n",
       "981907    378          2 2013-01-01      0          0     0      0       Public              1  Tue     1   Jan        1  2013\n",
       "981906    377          2 2013-01-01      0          0     0      0       Public              1  Tue     1   Jan        1  2013\n",
       "981905    376          2 2013-01-01      0          0     0      0       Public              1  Tue     1   Jan        1  2013"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb50e7c-f4b8-4078-81d6-2c9610c55003",
   "metadata": {},
   "source": [
    "#### 4.3. StateHoliday Impact Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "496247e1-a33f-4cfa-9104-5d75e1e43b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  stateholiday  avg_customers  avg_sales\n",
      "2         None         652.11    5940.39\n",
      "3       Public          43.82     290.74\n",
      "1       Easter          36.56     214.31\n",
      "0    Christmas          27.17     168.73\n",
      "Number of closed times during holidays: \u001b[1m30140\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Create summary table for holiday impact\n",
    "stateholiday_analysis = (\n",
    "    df_features\n",
    "    .groupby(\"stateholiday\")[[\"customers\", \"sales\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"customers\": \"avg_customers\", \"sales\": \"avg_sales\"})\n",
    "    .sort_values(by=\"avg_sales\", ascending=False)\n",
    ")\n",
    "\n",
    "print(stateholiday_analysis)\n",
    "\n",
    "# Count times stores were closed during holidays (using temp labels)\n",
    "closed_holiday_days = df_features[(df_features[\"open\"] == 0) & (df_features.stateholiday != \"None\")].shape[0]\n",
    "print(f\"Number of closed times during holidays: {bold_start}{closed_holiday_days}{bold_end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c19df8-8a2f-4810-8d11-13a4b68a3fe0",
   "metadata": {},
   "source": [
    "#### 4.4. Day & Seasonality Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "209144f0-fbd7-41ea-a976-410804f36441",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   day  avg_customers  avg_sales\n",
      "1  Mon         812.93    7797.64\n",
      "5  Tue         761.86    7005.52\n",
      "0  Fri         742.53    6703.50\n",
      "6  Wed         721.20    6536.45\n",
      "4  Thu         695.78    6216.11\n",
      "2  Sat         658.76    5856.78\n",
      "3  Sun          35.58     202.62\n"
     ]
    }
   ],
   "source": [
    "day_analysis = (\n",
    "    df_features\n",
    "    .groupby(\"day\")[[\"customers\",\"sales\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"customers\": \"avg_customers\",\"sales\": \"avg_sales\"})\n",
    "    .sort_values(by=\"avg_sales\", ascending=False)\n",
    ")\n",
    "\n",
    "print(day_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c56ac0-aec4-46ff-afac-8c8118b9352d",
   "metadata": {},
   "source": [
    "#### 4.5. Month & Seasonality Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f509d8e8-5300-4133-a5e1-3c26ce1b4fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   month  avg_customers  avg_sales\n",
      "2    Dec         703.07    6826.61\n",
      "5    Jul         663.59    6022.61\n",
      "9    Nov         654.15    6008.11\n",
      "7    Mar         629.40    5784.58\n",
      "6    Jun         624.79    5760.96\n",
      "0    Apr         630.61    5738.87\n",
      "1    Aug         642.50    5693.02\n",
      "3    Feb         626.72    5645.25\n",
      "11   Sep         634.44    5570.25\n",
      "10   Oct         631.10    5537.04\n",
      "8    May         601.99    5489.64\n",
      "4    Jan         601.62    5465.40\n"
     ]
    }
   ],
   "source": [
    "\n",
    "month_analysis = (\n",
    "    df_features\n",
    "    .groupby(\"month\")[[\"customers\",\"sales\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"sales\": \"avg_sales\", \"customers\": \"avg_customers\"})\n",
    "    .sort_values(by=\"avg_sales\", ascending=False)\n",
    ")\n",
    "\n",
    "print(month_analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8795851d-8333-4227-9f7c-280c30e35c8f",
   "metadata": {},
   "source": [
    "#### 4.6. Year & Seasonality Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b8b2c369-3d60-48f3-ba08-c4fe19e420a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  avg_customers  avg_sales\n",
      "1  2014         643.27    5833.29\n",
      "2  2015         620.84    5832.95\n",
      "0  2013         629.04    5658.53\n"
     ]
    }
   ],
   "source": [
    "\n",
    "year_analysis = (\n",
    "    df_features\n",
    "    .groupby(\"year\")[[\"customers\", \"sales\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"sales\": \"avg_sales\", \"customers\": \"avg_customers\"})\n",
    "    .sort_values(by=\"avg_sales\", ascending=False)\n",
    ")\n",
    "\n",
    "print(year_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c731b370-60a0-4a4e-b4fd-ee84426a0329",
   "metadata": {},
   "source": [
    "#### 4.5. Promo √ó DayOfWeek Interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2fa19dca-b5ee-4825-b390-1be8547bbc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    promo  day  avg_customers  avg_sales\n",
      "8       1  Mon         938.67    9709.13\n",
      "10      1  Tue         837.47    8226.49\n",
      "11      1  Wed         785.91    7540.85\n",
      "9       1  Thu         774.00    7241.50\n",
      "7       1  Fri         765.53    7168.90\n",
      "0       0  Fri         716.68    6180.31\n",
      "2       0  Sat         658.76    5856.78\n",
      "5       0  Tue         675.35    5608.49\n",
      "1       0  Mon         666.24    5567.56\n",
      "6       0  Wed         648.26    5404.23\n",
      "4       0  Thu         607.85    5063.39\n",
      "3       0  Sun          35.58     202.62\n"
     ]
    }
   ],
   "source": [
    "promo_dow_analysis = (\n",
    "    df_features\n",
    "    .groupby([\"promo\", \"day\"])[[\"customers\", \"sales\",]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"sales\": \"avg_sales\", \"customers\": \"avg_customers\"})\n",
    "    .sort_values(by=\"avg_sales\", ascending=False)\n",
    ")\n",
    "\n",
    "print(promo_dow_analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e1b146fa-a040-4799-b46c-d2a9ba93b5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    promo  promo_flag  day  avg_customers  avg_sales\n",
      "8       1        True  Mon         938.67    9709.13\n",
      "10      1        True  Tue         837.47    8226.49\n",
      "11      1        True  Wed         785.91    7540.85\n",
      "9       1        True  Thu         774.00    7241.50\n",
      "7       1        True  Fri         765.53    7168.90\n",
      "0       0       False  Fri         716.68    6180.31\n",
      "2       0       False  Sat         658.76    5856.78\n",
      "5       0       False  Tue         675.35    5608.49\n",
      "1       0       False  Mon         666.24    5567.56\n",
      "6       0       False  Wed         648.26    5404.23\n",
      "4       0       False  Thu         607.85    5063.39\n",
      "3       0       False  Sun          35.58     202.62\n"
     ]
    }
   ],
   "source": [
    "# Create a copy to avoid modifying the original DataFrame\n",
    "df_temp = df_features.copy()\n",
    "\n",
    "# Insert promo_flag immediately after the 'promo' column\n",
    "promo_index = df_temp.columns.get_loc(\"promo\")\n",
    "df_temp.insert(promo_index + 1, \"promo_flag\", df_temp[\"promo\"] == 1)\n",
    "\n",
    "promo_dow_analysis = (\n",
    "    df_temp\n",
    "    .groupby([\"promo\", \"promo_flag\", \"day\"])[[\"customers\", \"sales\"]]\n",
    "    .mean()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"sales\": \"avg_sales\", \"customers\": \"avg_customers\"})\n",
    "    .sort_values(by=\"avg_sales\", ascending=False)\n",
    ")\n",
    "\n",
    "print(promo_dow_analysis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dbaa0a-cb4f-4bd4-8796-17c0df794500",
   "metadata": {},
   "source": [
    "### Quarterly Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4e4635e9-d9a9-4927-979a-8e3c35025777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quarterly Sales Analysis:\n",
      "==================================================\n",
      "Quarter    Avg Sales    Rank   vs Q1   \n",
      "--------------------------------------------------\n",
      "Q4         ‚Ç¨   6,125    1      +8.8%   \n",
      "Q3         ‚Ç¨   5,764    2      +2.4%   \n",
      "Q2         ‚Ç¨   5,661    3      +0.5%   \n",
      "Q1         ‚Ç¨   5,631    4      Base    \n",
      "\n",
      "Quarterly Summary:\n",
      "--------------------\n",
      "Best quarter: Q4 (‚Ç¨6,125)\n",
      "Worst quarter: Q1 (‚Ç¨5,631)\n",
      "Performance gap: 8.5%\n",
      "\n",
      "Quarter-to-Quarter Growth:\n",
      "-------------------------\n",
      "Q1 to Q2: +0.5%\n",
      "Q2 to Q3: +1.8%\n",
      "Q3 to Q4: +6.3%\n",
      "\n",
      "Key Insight: Q4 generates 26.4% of annual revenue\n"
     ]
    }
   ],
   "source": [
    "# Simple and robust quarterly analysis\n",
    "quarter_avg = df_features.groupby('quarter')['sales'].mean().sort_values(ascending=False)\n",
    "\n",
    "print(\"Quarterly Sales Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"{'Quarter':<10} {'Avg Sales':<12} {'Rank':<6} {'vs Q1':<8}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i, (quarter, sales) in enumerate(quarter_avg.items(), 1):\n",
    "    vs_q1 = ((sales - quarter_avg[1]) / quarter_avg[1]) * 100\n",
    "    vs_q1_str = f\"{vs_q1:+.1f}%\" if quarter != 1 else \"Base\"\n",
    "    print(f\"Q{quarter:<9} ‚Ç¨{sales:>8,.0f}    {i:<6} {vs_q1_str:<8}\")\n",
    "\n",
    "print(f\"\\nQuarterly Summary:\")\n",
    "print(\"-\" * 20)\n",
    "best_q = quarter_avg.index[0]\n",
    "worst_q = quarter_avg.index[-1]\n",
    "range_pct = ((quarter_avg.max() - quarter_avg.min()) / quarter_avg.mean()) * 100\n",
    "\n",
    "print(f\"Best quarter: Q{best_q} (‚Ç¨{quarter_avg[best_q]:,.0f})\")\n",
    "print(f\"Worst quarter: Q{worst_q} (‚Ç¨{quarter_avg[worst_q]:,.0f})\")\n",
    "print(f\"Performance gap: {range_pct:.1f}%\")\n",
    "\n",
    "# Growth pattern\n",
    "print(f\"\\nQuarter-to-Quarter Growth:\")\n",
    "print(\"-\" * 25)\n",
    "for q in [2, 3, 4]:\n",
    "    growth = ((quarter_avg[q] - quarter_avg[q-1]) / quarter_avg[q-1]) * 100\n",
    "    print(f\"Q{q-1} to Q{q}: {growth:+.1f}%\")\n",
    "\n",
    "print(f\"\\nKey Insight: Q{best_q} generates {((quarter_avg[best_q]/quarter_avg.sum())*100):.1f}% of annual revenue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e726ba-7b9f-4f27-8270-666a57430978",
   "metadata": {},
   "source": [
    "# ‚ú® Pro Tips : Reusable Functions - Best Practices for Reusable Functions in Data Analysis\n",
    "-----------\n",
    "Reusable functions streamline analytical workflows by promoting consistency, reducing redundancy, and improving maintainability. To maximize their effectiveness:\n",
    "\n",
    " - Design for flexibility: Use parameters and config objects to adapt logic across datasets and use cases.\n",
    "\n",
    " - Keep functions atomic: Focus each function on a single task‚Äîcleaning, aggregating, visualizing, or exporting.\n",
    "\n",
    " - Avoid side effects: Return outputs explicitly; defer file I/O or plotting to higher-level orchestration.\n",
    "\n",
    " - Document clearly: Use concise docstrings and intuitive naming for better readability and future reuse.\n",
    "\n",
    " - Centralize configuration: Store defaults and settings in external files or global dictionaries for easy updates.\n",
    "\n",
    " - Efficient function design leads to cleaner notebooks, faster iteration, and scalable analysis pipelines.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6574dab5-f9a9-4670-b2a3-754052bc1fe8",
   "metadata": {},
   "source": [
    "# üîß Generalized Reusable Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "997a27e3-64bd-44d3-b440-09954ede4710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_by_time(df, time_col, metrics, agg_func='mean', rename_prefix='avg', sort_by=None, ascending=False):\n",
    "    \"\"\"\n",
    "    General-purpose time-based aggregation summary.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "    - time_col: column to group by (e.g., 'year', 'month', 'dayofweek')\n",
    "    - metrics: list of metric columns to aggregate (e.g., ['sales', 'customers'])\n",
    "    - agg_func: aggregation function (default: 'mean')\n",
    "    - rename_prefix: prefix added to aggregated column names\n",
    "    - sort_by: column to sort by (e.g., 'avg_sales')\n",
    "    - ascending: sorting direction (default: descending)\n",
    "\n",
    "    Returns:\n",
    "    - Aggregated and optionally sorted DataFrame\n",
    "    \"\"\"\n",
    "    summary = (\n",
    "        df.groupby(time_col)[metrics]\n",
    "        .agg(agg_func)\n",
    "        .reset_index()\n",
    "        .rename(columns={metric: f\"{rename_prefix}_{metric}\" for metric in metrics})\n",
    "    )\n",
    "\n",
    "    if sort_by:\n",
    "        summary = summary.sort_values(by=sort_by, ascending=ascending)\n",
    "\n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "796c2951-c5e8-496d-a141-63308ba40e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   day  avg_customers  avg_sales\n",
      "1  Mon         812.93    7797.64\n",
      "5  Tue         761.86    7005.52\n",
      "0  Fri         742.53    6703.50\n",
      "6  Wed         721.20    6536.45\n",
      "4  Thu         695.78    6216.11\n",
      "2  Sat         658.76    5856.78\n",
      "3  Sun          35.58     202.62\n"
     ]
    }
   ],
   "source": [
    "day_analysis = summarize_by_time(\n",
    "    df=df_features,\n",
    "    time_col='day',\n",
    "    metrics=['customers', 'sales'],\n",
    "    agg_func='mean',\n",
    "    rename_prefix='avg',\n",
    "    sort_by='avg_sales',\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "print(day_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dbe26d45-07f0-4021-9444-4f812133e0ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   month  avg_customers  avg_sales\n",
      "2    Dec         703.07    6826.61\n",
      "5    Jul         663.59    6022.61\n",
      "9    Nov         654.15    6008.11\n",
      "7    Mar         629.40    5784.58\n",
      "6    Jun         624.79    5760.96\n",
      "0    Apr         630.61    5738.87\n",
      "1    Aug         642.50    5693.02\n",
      "3    Feb         626.72    5645.25\n",
      "11   Sep         634.44    5570.25\n",
      "10   Oct         631.10    5537.04\n",
      "8    May         601.99    5489.64\n",
      "4    Jan         601.62    5465.40\n"
     ]
    }
   ],
   "source": [
    "month_analysis = summarize_by_time(\n",
    "    df=df_features,\n",
    "    time_col='month',\n",
    "    metrics=['customers', 'sales'],\n",
    "    agg_func='mean',\n",
    "    rename_prefix='avg',\n",
    "    sort_by='avg_sales',\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "print(month_analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "33db20cc-e7d9-477d-a1f7-3b1536d56a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  avg_customers  avg_sales\n",
      "1  2014         643.27    5833.29\n",
      "2  2015         620.84    5832.95\n",
      "0  2013         629.04    5658.53\n"
     ]
    }
   ],
   "source": [
    "year_analysis = summarize_by_time(\n",
    "    df=df_features,\n",
    "    time_col='year',\n",
    "    metrics=['customers', 'sales'],\n",
    "    agg_func='mean',\n",
    "    rename_prefix='avg',\n",
    "    sort_by='avg_sales',\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "print(year_analysis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "571b6b1d-ba96-4299-a935-6d4a8bcfcfc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'train_df' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "# To pull train_df from one notebook to another in JupyterLab\n",
    "%store train_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b33402-11dd-471a-b9c2-effe7f65283b",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4734fdac-47a4-4b96-9633-c77a9fd333be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data Ingestion and Exploratory Data Analysis completed successfully!\n",
      "üóìÔ∏è Analysis Date: \u001b[1m2025-08-07 00:37:34\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"‚úÖ Data Ingestion and Exploratory Data Analysis completed successfully!\")\n",
    "print(f\"üóìÔ∏è Analysis Date: {bold_start}{pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}{bold_end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fb3d94-675d-4cea-bc83-2e995e1e8c94",
   "metadata": {},
   "source": [
    "--------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2a578a31-6bf1-4605-8d14-c69c3df0809c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã Analysis Summary\n",
      "üü¢ Begin Date: \u001b[1m2025-08-07 00:37:22\u001b[0m\n",
      "‚úÖ End Date:   \u001b[1m2025-08-07 00:37:34\u001b[0m\n",
      "‚è±Ô∏è Duration:   \u001b[1m0 days 00:00:11.928102\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# End analysis\n",
    "analysis_end = pd.Timestamp.now()\n",
    "duration = analysis_end - analysis_begin\n",
    "\n",
    "# Final summary print\n",
    "print(\"\\nüìã Analysis Summary\")\n",
    "print(f\"üü¢ Begin Date: {bold_start}{analysis_begin.strftime('%Y-%m-%d %H:%M:%S')}{bold_end}\")\n",
    "print(f\"‚úÖ End Date:   {bold_start}{analysis_end.strftime('%Y-%m-%d %H:%M:%S')}{bold_end}\")\n",
    "print(f\"‚è±Ô∏è Duration:   {bold_start}{str(duration)}{bold_end}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045b4131-f856-44b5-81e8-1f72274952fa",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "## Project Design Rationale: Notebook Separation\n",
    "\n",
    "To promote **clarity, maintainability, and scalability** within the project, **data engineering** and **visualization tasks** are intentionally separated into distinct notebooks. This modular approach prevents the accumulation of excessive code in a single notebook, making it easier to **debug, update, and collaborate across different stages of the workflow**. By isolating data transformation logic from visual analysis, **each notebook remains focused and purpose-driven**, ultimately **enhancing the overall efficiency and readability of the project**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "911a5140-e2f8-414a-bea9-7613a656a305",
   "metadata": {},
   "source": [
    "\n",
    "ARNAUD DAVY - MUKWA NDUDI\n",
    "-----------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
